{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Packages\n",
    "Recommended to use [Anaconda](https://www.anaconda.com/l) in combination with an environment. Installation commands for all required packages can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Anaconda\n",
    "!conda install ipykernel requests pandas numpy scikit-learn nltk matplotlib pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "!pip install wget \n",
    "\n",
    "# Without Anaconda\n",
    "# !pip install wget ipykernel requests pandas numpy scikit-learn nltk matplotlib torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "Select and download datasets.  \n",
    "  \n",
    "All downloads are hosted on own Nextcloud server for consistently good performance. For dataset references please see links below.\n",
    "\n",
    "Available datasets:  \n",
    "[0](http://help.sentiment140.com/for-students) - 1,600,000 automatically labelled tweets.  \n",
    "[1](https://nlp.stanford.edu/sentiment/code.html) - 10,605 manually labelled Rotten Tomatoes reviews.  \n",
    "[2](https://ieee-dataport.org/open-access/stock-market-tweets-data#files) - 1,300 manually labelled financial tweets.  \n",
    "[3](https://arxiv.org/abs/1307.5336) - 4,840 manually labelled fiancial news headlines.  \n",
    "[4](https://github.com/ajayshewale/Sentiment-Analysis-of-Text-Data-Tweets-) - 5,970 manually labelled financial tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os\n",
    "\n",
    "# Select databases you want to use for training the model\n",
    "DATASETS_SELECTED = [1,2,3,4]\n",
    "\n",
    "all_urls = [\"https://nextcloud.lucashost.nl/s/QEDjzxCQidDZDR4/download/trainingandtestdata.zip\", \"https://nextcloud.lucashost.nl/s/e5tyPSHs9Lrc3bT/download/stanfordSentimentTreebank.zip\", \"https://nextcloud.lucashost.nl/s/bm8bqeKqdyFqiTe/download/tweets.zip\", \"https://nextcloud.lucashost.nl/s/2b4tNYKQp9jP7Bn/download/archive.zip\", \"https://nextcloud.lucashost.nl/s/tdC65kRGWzYzeP2/download/punkt.zip\"]\n",
    "urls = [all_urls[i] for i in DATASETS_SELECTED]\n",
    "path = \"datasets/\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "  os.makedirs(path)\n",
    "\n",
    "for url in urls:\n",
    "    split_url = url.split(\"/\")\n",
    "    if not (os.path.exists(path + split_url[-1])):\n",
    "      wget.download(url, out = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(path + filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the differrent datasets and integrate them with eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23417</th>\n",
       "      <td>Ok ed let's do this, Zlatan, greizmann and Lap...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23418</th>\n",
       "      <td>Goal level: Zlatan  90k by Friday? = Posting e...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23419</th>\n",
       "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23420</th>\n",
       "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23421</th>\n",
       "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23422 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence Sentiment\n",
       "0      The Rock is destined to be the 21st Century 's...   neutral\n",
       "1      The gorgeously elaborate continuation of `` Th...   neutral\n",
       "2                         Effective but too-tepid biopic   neutral\n",
       "3      If you sometimes like to go to the movies to h...   neutral\n",
       "4      Emerges as something rare , an issue movie tha...  negative\n",
       "...                                                  ...       ...\n",
       "23417  Ok ed let's do this, Zlatan, greizmann and Lap...  positive\n",
       "23418  Goal level: Zlatan  90k by Friday? = Posting e...   neutral\n",
       "23419  @YouAreMyArsenal Wouldn't surprise me if we en...   neutral\n",
       "23420  Rib injury for Zlatan against Russia is a big ...   neutral\n",
       "23421  Noooooo! I was hoping to see Zlatan being Zlat...   neutral\n",
       "\n",
       "[23422 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in DATASETS_SELECTED:\n",
    "    if (i == 0):\n",
    "        df1_manual = pd.read_csv(path + \"testdata.manual.2009.06.14.csv\", names=['Sentiment', 'Sentence'], usecols=[0, 5])\n",
    "        df1_auto = pd.read_csv(path + \"training.1600000.processed.noemoticon.csv\", names=['Sentiment', 'Sentence'], usecols=[0, 5], encoding='ISO-8859-1')\n",
    "        df1 = df1_auto.append(df1_manual, ignore_index=True)\n",
    "        df1[\"Sentiment\"] = df1[\"Sentiment\"].apply(lambda sentiment: \"negative\" if sentiment == 0 else (\"neutral\" if sentiment == 2 else \"positive\"))\n",
    "        df = df.append(df1, ignore_index=True)\n",
    "    elif (i ==1):\n",
    "        df2_sentence = pd.read_csv(path + \"stanfordSentimentTreebank/datasetSentences.txt\", sep=\"\\t\")\n",
    "        df2_sentiment = pd.read_csv(path + \"stanfordSentimentTreebank/sentiment_labels.txt\", sep=\"|\")\n",
    "        df2 = pd.merge(df2_sentence, df2_sentiment, left_on=\"sentence_index\", right_on=\"phrase ids\")\n",
    "        df2 = df2.drop(columns=[\"sentence_index\", \"phrase ids\"])\n",
    "        df2 = df2.rename(columns={\"sentiment values\": \"Sentiment\", \"sentence\": \"Sentence\"})\n",
    "        df2[\"Sentiment\"] = df2[\"Sentiment\"].apply(lambda sentiment: \"negative\" if sentiment < 0.4 else (\"neutral\" if sentiment <= 0.6 else \"positive\"))\n",
    "        df = df.append(df2, ignore_index=True)\n",
    "    elif (i ==2):\n",
    "        df3 = pd.read_csv(path + \"tweets/tweets_labelled_09042020_16072020.csv\", sep=\";\", on_bad_lines=\"skip\")\n",
    "        df3 = df3.drop(columns=[\"id\", \"created_at\"])\n",
    "        df3 = df3.rename(columns={\"sentiment\": \"Sentiment\", \"text\": \"Sentence\"})\n",
    "        df3 = df3.dropna()\n",
    "        df = df.append(df3, ignore_index=True)\n",
    "    elif (i == 3):\n",
    "        df4 = pd.read_csv(path + 'all-data.csv', names=['Sentiment', 'Sentence'], encoding='ISO-8859-1')\n",
    "        df4['Sentiment'] = df4['Sentiment'].astype('string')\n",
    "        df4['Sentence'] = df4['Sentence'].astype('string')\n",
    "        df = df.append(df4, ignore_index=True)\n",
    "    elif (i == 4):\n",
    "        df5 = pd.read_csv(path + \"train.csv\")\n",
    "        df5 = df5.drop(columns=[\"Id\"])\n",
    "        df5 = df5.dropna()\n",
    "        df5 = df5[df5[\"Tweet\"] != \"Not Available\"]\n",
    "        df5 = df5[df5[\"Category\"] != \"Tweet\"]\n",
    "        df5 = df5.rename(columns={\"Category\": \"Sentiment\", \"Tweet\": \"Sentence\"})\n",
    "        df = df.append(df5, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Database \" + str(i) + \" not found\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentences are normalized, over- and/or undersampled, stemmed, tokenized and encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(sentence):\n",
    "    link_re_pattern = \"https?:\\/\\/t.co/[\\w]+\"\n",
    "    mention_re_pattern = \"@\\w+\"\n",
    "    enter_re_pattern = \"\\n\"\n",
    "    sentence = re.sub(link_re_pattern, \"\", sentence)\n",
    "    sentence = re.sub(mention_re_pattern, \"\", sentence)\n",
    "    sentence = re.sub(enter_re_pattern, \" \", sentence)\n",
    "    return sentence.lower()\n",
    "\n",
    "df[\"Sentence\"] = df[\"Sentence\"].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    8065\n",
       "positive    8065\n",
       "neutral     8065\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much you oversample compared to undersampling\n",
    "FACTOR = 0.5\n",
    "\n",
    "oversample_rate = math.floor((df[\"Sentiment\"].value_counts()[0] - df[\"Sentiment\"].value_counts()[-1]) * FACTOR)\n",
    "undersample_rate = math.ceil((df[\"Sentiment\"].value_counts()[0] - df[\"Sentiment\"].value_counts()[-1]) * (1 - FACTOR))\n",
    "\n",
    "most_df = df[df[\"Sentiment\"] == df[\"Sentiment\"].value_counts().index[0]]\n",
    "mid_df = df[df[\"Sentiment\"] == df[\"Sentiment\"].value_counts().index[1]]\n",
    "least_df = df[df[\"Sentiment\"] == df[\"Sentiment\"].value_counts().index[2]]\n",
    "\n",
    "drop_indices = np.random.choice(most_df.index, size=undersample_rate, replace=False)\n",
    "undersampled = most_df.drop(drop_indices, axis=0)\n",
    "oversampled = least_df.append(least_df.sample(oversample_rate, replace=True))\n",
    "\n",
    "midsample_rate = oversampled[\"Sentiment\"].value_counts()[0] - mid_df[\"Sentiment\"].value_counts()[0]\n",
    "\n",
    "if (midsample_rate < 0):\n",
    "    mid_drop_indices = np.random.choice(mid_df.index, -midsample_rate, replace=False)\n",
    "    midsampled = mid_df.drop(mid_drop_indices)\n",
    "else:\n",
    "    midsampled = mid_df.append(mid_df.sample(midsample_rate, replace=True))\n",
    "\n",
    "balanced_df = pd.concat([oversampled, midsampled, undersampled])\n",
    "balanced_df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter_stemmer  = PorterStemmer()\n",
    "\n",
    "def tokenization(sentence):\n",
    "    sentence = word_tokenize(sentence)\n",
    "    for idx, word in enumerate(sentence):\n",
    "        sentence[idx] = porter_stemmer.stem(word)\n",
    "    return sentence\n",
    "\n",
    "balanced_df[\"Sentence\"] = balanced_df[\"Sentence\"].apply(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<SOS>', '<EOS>', 'emerg', 'as', 'someth', 'rare', ',', 'an', 'issu', 'movi', 'that', \"'s\", 'so', 'honest', 'and', 'keenli', 'observ', 'it', 'doe', \"n't\", 'feel', 'like', 'one', '.', 'perhap', 'no', 'pictur', 'ever', 'made', 'ha', 'more', 'liter', 'show', 'the', 'road', 'to', 'hell', 'is', 'pave', 'with', 'good', 'intent', 'thi', 'a', 'film', 'well', 'worth', 'see', 'talk']\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "\n",
    "for index, row in balanced_df.iterrows():\n",
    "    for token in row[\"Sentence\"]:\n",
    "        if token not in index2word:\n",
    "                index2word.append(token)\n",
    "\n",
    "word2index = {token: idx for idx, token in enumerate(index2word)}\n",
    "print(list(islice(word2index, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_map(sentiment):\n",
    "    if sentiment == \"negative\":\n",
    "        return 0\n",
    "    elif sentiment == \"neutral\":\n",
    "        return 1\n",
    "    else: #positive\n",
    "        return 2\n",
    "\n",
    "def encode_and_pad(sentence, length):\n",
    "    sos = [word2index[\"<SOS>\"]]\n",
    "    eos = [word2index[\"<EOS>\"]]\n",
    "    pad = [word2index[\"<PAD>\"]]\n",
    "    encoded = []\n",
    "\n",
    "    if len(sentence) < length - 2: # -2 for SOS and EOS\n",
    "        n_pads = length - 2 - len(sentence)\n",
    "        for w in sentence:\n",
    "            try:\n",
    "                encoded.append(word2index[w])\n",
    "            except:\n",
    "                encoded.append(word2index[\"<PAD>\"])\n",
    "        # encoded = [word2index[w] for w in sentence]\n",
    "        return sos + encoded + eos + pad * n_pads \n",
    "    else: # sentence is longer than possible; truncating\n",
    "        for w in sentence:\n",
    "            try:\n",
    "                encoded.append(word2index[w])\n",
    "            except:\n",
    "                encoded.append(word2index[\"<PAD>\"])\n",
    "        # encoded = [word2index[w] for w in sentence]\n",
    "        truncated = encoded[:length - 2]\n",
    "        return sos + truncated + eos\n",
    "\n",
    "SEQ_LENGTH = 32\n",
    "\n",
    "encoded = [(encode_and_pad(row[\"Sentence\"], SEQ_LENGTH), sentiment_map(row[\"Sentiment\"])) for index, row in balanced_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TEST_SIZE = 0.15\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "train_encoded, test_encoded = train_test_split(encoded, test_size=TEST_SIZE)\n",
    "\n",
    "train_x = np.array([sentence for sentence, sentiment in train_encoded])\n",
    "train_y = np.array([sentiment for sentence, sentiment in train_encoded])\n",
    "test_x = np.array([sentence for sentence, sentiment in test_encoded])\n",
    "test_y = np.array([sentiment for sentence, sentiment in test_encoded])\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# drop_last is used to drop the final batch if does not have BATCH_SIZE elements\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_dl = DataLoader(test_ds, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "Create a LSTM neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LSTM_Sentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 3)\n",
    "    def forward(self, x, hidden):\n",
    "        embs = self.embedding(x)\n",
    "        out, hidden = self.lstm(embs, hidden)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        # We extract the scores for the final hidden state\n",
    "        out = out[:, -1]\n",
    "        return out, hidden\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_dim), torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "model = LSTM_Sentiment(len(word2index), 64, 32, 1, 0.2)\n",
    "# model = model.to(dtype=torch.double)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LSTM neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0  /411, time: 0.028s, loss: 1.099, acc: 0.360\n",
      "epoch: 0, batch: 103/411, time: 0.655s, loss: 1.090, acc: 0.480\n",
      "epoch: 0, batch: 206/411, time: 1.139s, loss: 1.097, acc: 0.400\n",
      "epoch: 0, batch: 309/411, time: 1.619s, loss: 1.114, acc: 0.320\n",
      "Accuracy on the test set: 0.386\n",
      "epoch: 1, batch: 0  /411, time: 2.239s, loss: 1.070, acc: 0.320\n",
      "epoch: 1, batch: 103/411, time: 2.725s, loss: 1.120, acc: 0.320\n",
      "epoch: 1, batch: 206/411, time: 3.214s, loss: 1.041, acc: 0.560\n",
      "epoch: 1, batch: 309/411, time: 3.692s, loss: 1.072, acc: 0.280\n",
      "Accuracy on the test set: 0.409\n",
      "epoch: 2, batch: 0  /411, time: 4.313s, loss: 1.071, acc: 0.360\n",
      "epoch: 2, batch: 103/411, time: 4.790s, loss: 1.088, acc: 0.400\n",
      "epoch: 2, batch: 206/411, time: 5.267s, loss: 0.996, acc: 0.520\n",
      "epoch: 2, batch: 309/411, time: 5.742s, loss: 1.077, acc: 0.440\n",
      "Accuracy on the test set: 0.448\n",
      "epoch: 3, batch: 0  /411, time: 6.364s, loss: 0.939, acc: 0.400\n",
      "epoch: 3, batch: 103/411, time: 6.858s, loss: 0.762, acc: 0.680\n",
      "epoch: 3, batch: 206/411, time: 7.350s, loss: 0.928, acc: 0.440\n",
      "epoch: 3, batch: 309/411, time: 7.835s, loss: 0.908, acc: 0.600\n",
      "Accuracy on the test set: 0.483\n",
      "epoch: 4, batch: 0  /411, time: 8.457s, loss: 0.795, acc: 0.640\n",
      "epoch: 4, batch: 103/411, time: 8.937s, loss: 0.845, acc: 0.540\n",
      "epoch: 4, batch: 206/411, time: 9.416s, loss: 0.752, acc: 0.620\n",
      "epoch: 4, batch: 309/411, time: 9.899s, loss: 0.741, acc: 0.680\n",
      "Accuracy on the test set: 0.506\n",
      "epoch: 5, batch: 0  /411, time: 10.520s, loss: 0.715, acc: 0.660\n",
      "epoch: 5, batch: 103/411, time: 11.000s, loss: 0.689, acc: 0.720\n",
      "epoch: 5, batch: 206/411, time: 11.479s, loss: 0.543, acc: 0.820\n",
      "epoch: 5, batch: 309/411, time: 11.958s, loss: 0.673, acc: 0.700\n",
      "Accuracy on the test set: 0.523\n",
      "epoch: 6, batch: 0  /411, time: 12.571s, loss: 0.664, acc: 0.700\n",
      "epoch: 6, batch: 103/411, time: 13.036s, loss: 0.736, acc: 0.740\n",
      "epoch: 6, batch: 206/411, time: 13.503s, loss: 0.610, acc: 0.740\n",
      "epoch: 6, batch: 309/411, time: 13.967s, loss: 0.819, acc: 0.720\n",
      "Accuracy on the test set: 0.537\n",
      "epoch: 7, batch: 0  /411, time: 14.565s, loss: 0.454, acc: 0.900\n",
      "epoch: 7, batch: 103/411, time: 15.030s, loss: 0.597, acc: 0.760\n",
      "epoch: 7, batch: 206/411, time: 15.496s, loss: 0.475, acc: 0.840\n",
      "epoch: 7, batch: 309/411, time: 15.965s, loss: 0.498, acc: 0.780\n",
      "Accuracy on the test set: 0.554\n",
      "epoch: 8, batch: 0  /411, time: 16.564s, loss: 0.384, acc: 0.880\n",
      "epoch: 8, batch: 103/411, time: 17.031s, loss: 0.366, acc: 0.920\n",
      "epoch: 8, batch: 206/411, time: 17.497s, loss: 0.317, acc: 0.900\n",
      "epoch: 8, batch: 309/411, time: 17.961s, loss: 0.469, acc: 0.820\n",
      "Accuracy on the test set: 0.562\n",
      "epoch: 9, batch: 0  /411, time: 18.565s, loss: 0.438, acc: 0.800\n",
      "epoch: 9, batch: 103/411, time: 19.039s, loss: 0.577, acc: 0.800\n",
      "epoch: 9, batch: 206/411, time: 19.515s, loss: 0.459, acc: 0.840\n",
      "epoch: 9, batch: 309/411, time: 19.980s, loss: 0.283, acc: 0.880\n",
      "Accuracy on the test set: 0.571\n",
      "epoch: 10, batch: 0  /411, time: 20.577s, loss: 0.264, acc: 0.940\n",
      "epoch: 10, batch: 103/411, time: 21.041s, loss: 0.419, acc: 0.820\n",
      "epoch: 10, batch: 206/411, time: 21.508s, loss: 0.253, acc: 0.920\n",
      "epoch: 10, batch: 309/411, time: 21.973s, loss: 0.270, acc: 0.940\n",
      "Accuracy on the test set: 0.573\n",
      "epoch: 11, batch: 0  /411, time: 22.577s, loss: 0.374, acc: 0.820\n",
      "epoch: 11, batch: 103/411, time: 23.042s, loss: 0.679, acc: 0.800\n",
      "epoch: 11, batch: 206/411, time: 23.506s, loss: 0.373, acc: 0.860\n",
      "epoch: 11, batch: 309/411, time: 23.969s, loss: 0.447, acc: 0.880\n",
      "Accuracy on the test set: 0.572\n",
      "epoch: 12, batch: 0  /411, time: 24.566s, loss: 0.255, acc: 0.880\n",
      "epoch: 12, batch: 103/411, time: 25.029s, loss: 0.298, acc: 0.880\n",
      "epoch: 12, batch: 206/411, time: 25.496s, loss: 0.240, acc: 0.920\n",
      "epoch: 12, batch: 309/411, time: 25.961s, loss: 0.119, acc: 1.000\n",
      "Accuracy on the test set: 0.578\n",
      "epoch: 13, batch: 0  /411, time: 26.558s, loss: 0.461, acc: 0.820\n",
      "epoch: 13, batch: 103/411, time: 27.023s, loss: 0.168, acc: 0.960\n",
      "epoch: 13, batch: 206/411, time: 27.485s, loss: 0.133, acc: 0.940\n",
      "epoch: 13, batch: 309/411, time: 27.948s, loss: 0.154, acc: 0.940\n",
      "Accuracy on the test set: 0.579\n",
      "epoch: 14, batch: 0  /411, time: 28.545s, loss: 0.204, acc: 0.920\n",
      "epoch: 14, batch: 103/411, time: 29.009s, loss: 0.321, acc: 0.900\n",
      "epoch: 14, batch: 206/411, time: 29.477s, loss: 0.182, acc: 0.980\n",
      "epoch: 14, batch: 309/411, time: 29.940s, loss: 0.260, acc: 0.920\n",
      "Accuracy on the test set: 0.593\n",
      "epoch: 15, batch: 0  /411, time: 30.539s, loss: 0.236, acc: 0.940\n",
      "epoch: 15, batch: 103/411, time: 31.003s, loss: 0.263, acc: 0.920\n",
      "epoch: 15, batch: 206/411, time: 31.467s, loss: 0.211, acc: 0.940\n",
      "epoch: 15, batch: 309/411, time: 31.936s, loss: 0.137, acc: 0.960\n",
      "Accuracy on the test set: 0.580\n",
      "epoch: 16, batch: 0  /411, time: 32.532s, loss: 0.102, acc: 0.960\n",
      "epoch: 16, batch: 103/411, time: 33.003s, loss: 0.249, acc: 0.920\n",
      "epoch: 16, batch: 206/411, time: 33.471s, loss: 0.266, acc: 0.940\n",
      "epoch: 16, batch: 309/411, time: 33.936s, loss: 0.191, acc: 0.920\n",
      "Accuracy on the test set: 0.580\n",
      "epoch: 17, batch: 0  /411, time: 34.535s, loss: 0.393, acc: 0.880\n",
      "epoch: 17, batch: 103/411, time: 35.006s, loss: 0.336, acc: 0.860\n",
      "epoch: 17, batch: 206/411, time: 35.471s, loss: 0.372, acc: 0.920\n",
      "epoch: 17, batch: 309/411, time: 35.937s, loss: 0.128, acc: 0.940\n",
      "Accuracy on the test set: 0.584\n",
      "epoch: 18, batch: 0  /411, time: 36.536s, loss: 0.078, acc: 0.960\n",
      "epoch: 18, batch: 103/411, time: 37.003s, loss: 0.257, acc: 0.940\n",
      "epoch: 18, batch: 206/411, time: 37.493s, loss: 0.235, acc: 0.940\n",
      "epoch: 18, batch: 309/411, time: 37.957s, loss: 0.090, acc: 1.000\n",
      "Accuracy on the test set: 0.579\n",
      "epoch: 19, batch: 0  /411, time: 38.558s, loss: 0.145, acc: 0.920\n",
      "epoch: 19, batch: 103/411, time: 39.023s, loss: 0.098, acc: 0.960\n",
      "epoch: 19, batch: 206/411, time: 39.487s, loss: 0.132, acc: 0.960\n",
      "epoch: 19, batch: 309/411, time: 39.950s, loss: 0.076, acc: 0.980\n",
      "Accuracy on the test set: 0.592\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "start=time.time()\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    h0, c0 =  model.init_hidden()\n",
    "\n",
    "    h0 = h0.to(device)\n",
    "    c0 = c0.to(device)\n",
    "\n",
    "    # Train mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dl):\n",
    "\n",
    "        input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            out, hidden = model(input, (h0, c0))\n",
    "            train_loss = criterion(out, target.long())\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "        correct = torch.sum(torch.eq(pred, target)).item()\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        if not batch_idx % (math.ceil(len(train_dl) / 4)):\n",
    "            print(f'epoch: {epoch}, batch: {batch_idx:<{len(str(len(train_dl)))}}/{len(train_dl)}, time: {elapsed:.3f}s, loss: {train_loss.item():.3f}, acc: {correct / BATCH_SIZE:.3f}')\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    batch_acc = []\n",
    "    for batch_idx, batch in enumerate(test_dl):\n",
    "\n",
    "        input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            out, hidden = model(input, (h0, c0))\n",
    "            _, preds = torch.max(out, 1)\n",
    "            preds = preds.to(device).tolist()\n",
    "            batch_acc.append(accuracy_score(preds, target.tolist()))\n",
    "\n",
    "            test_loss = criterion(out, target.long())\n",
    "\n",
    "    print(f'Accuracy on the test set: {sum(batch_acc)/len(batch_acc):.3f}')\n",
    "\n",
    "    test_losses.append(test_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(test_losses, label=\"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the test set: 0.591\n"
     ]
    }
   ],
   "source": [
    "batch_acc = []\n",
    "for batch_idx, batch in enumerate(test_dl):\n",
    "\n",
    "    input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        out, hidden = model(input, (h0, c0))\n",
    "        _, preds = torch.max(out, 1)\n",
    "        preds = preds.to(device).tolist()\n",
    "        batch_acc.append(accuracy_score(preds, target.tolist()))\n",
    "\n",
    "print(f'Final accuracy on the test set: {sum(batch_acc)/len(batch_acc):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_employee': False,\n",
       " 'seen_layout_switch': False,\n",
       " 'has_visited_new_profile': False,\n",
       " 'pref_no_profanity': True,\n",
       " 'has_external_account': False,\n",
       " 'pref_geopopular': '',\n",
       " 'seen_redesign_modal': False,\n",
       " 'pref_show_trending': True,\n",
       " 'subreddit': {'default_set': True,\n",
       "  'user_is_contributor': False,\n",
       "  'banner_img': '',\n",
       "  'restrict_posting': True,\n",
       "  'user_is_banned': False,\n",
       "  'free_form_reports': True,\n",
       "  'community_icon': None,\n",
       "  'show_media': True,\n",
       "  'icon_color': '',\n",
       "  'user_is_muted': False,\n",
       "  'display_name': 'u_Rubinjo_L',\n",
       "  'header_img': None,\n",
       "  'title': '',\n",
       "  'coins': 0,\n",
       "  'previous_names': [],\n",
       "  'over_18': False,\n",
       "  'icon_size': [256, 256],\n",
       "  'primary_color': '',\n",
       "  'icon_img': 'https://styles.redditmedia.com/t5_5ga0v8/styles/profileIcon_snoo7e1baabd-7daf-4774-a95d-92829e511322-headshot.png?width=256&amp;height=256&amp;crop=256:256,smart&amp;s=5bf6cac6695af43722caff15194db1958f1fc158',\n",
       "  'description': '',\n",
       "  'submit_link_label': '',\n",
       "  'header_size': None,\n",
       "  'restrict_commenting': False,\n",
       "  'subscribers': 0,\n",
       "  'submit_text_label': '',\n",
       "  'is_default_icon': False,\n",
       "  'link_flair_position': '',\n",
       "  'display_name_prefixed': 'u/Rubinjo_L',\n",
       "  'key_color': '',\n",
       "  'name': 't5_5ga0v8',\n",
       "  'is_default_banner': True,\n",
       "  'url': '/user/Rubinjo_L/',\n",
       "  'quarantine': False,\n",
       "  'banner_size': None,\n",
       "  'user_is_moderator': True,\n",
       "  'accept_followers': True,\n",
       "  'public_description': '',\n",
       "  'link_flair_enabled': False,\n",
       "  'disable_contributor_requests': False,\n",
       "  'subreddit_type': 'user',\n",
       "  'user_is_subscriber': False},\n",
       " 'pref_show_presence': True,\n",
       " 'snoovatar_img': 'https://i.redd.it/snoovatar/avatars/7e1baabd-7daf-4774-a95d-92829e511322.png',\n",
       " 'snoovatar_size': [380, 600],\n",
       " 'gold_expiration': None,\n",
       " 'has_gold_subscription': False,\n",
       " 'is_sponsor': False,\n",
       " 'num_friends': 0,\n",
       " 'features': {'mod_service_mute_writes': True,\n",
       "  'promoted_trend_blanks': True,\n",
       "  'show_amp_link': True,\n",
       "  'mweb_link_tab': {'owner': 'growth',\n",
       "   'variant': 'control_2',\n",
       "   'experiment_id': 404},\n",
       "  'is_email_permission_required': True,\n",
       "  'mod_awards': True,\n",
       "  'mweb_xpromo_revamp_v3': {'owner': 'growth',\n",
       "   'variant': 'control_1',\n",
       "   'experiment_id': 480},\n",
       "  'mweb_xpromo_revamp_v2': {'owner': 'growth',\n",
       "   'variant': 'treatment_1',\n",
       "   'experiment_id': 457},\n",
       "  'awards_on_streams': True,\n",
       "  'mweb_xpromo_modal_listing_click_daily_dismissible_ios': True,\n",
       "  'chat_subreddit': True,\n",
       "  'cookie_consent_banner': True,\n",
       "  'modlog_copyright_removal': True,\n",
       "  'do_not_track': True,\n",
       "  'mod_service_mute_reads': True,\n",
       "  'chat_user_settings': True,\n",
       "  'use_pref_account_deployment': True,\n",
       "  'mweb_xpromo_interstitial_comments_ios': True,\n",
       "  'mweb_xpromo_modal_listing_click_daily_dismissible_android': True,\n",
       "  'premium_subscriptions_table': True,\n",
       "  'mweb_xpromo_interstitial_comments_android': True,\n",
       "  'mweb_nsfw_xpromo': {'owner': 'growth',\n",
       "   'variant': 'control_1',\n",
       "   'experiment_id': 361},\n",
       "  'noreferrer_to_noopener': True,\n",
       "  'chat_group_rollout': True,\n",
       "  'resized_styles_images': True,\n",
       "  'spez_modal': True,\n",
       "  'mweb_sharing_clipboard': {'owner': 'growth',\n",
       "   'variant': 'control_2',\n",
       "   'experiment_id': 315},\n",
       "  'expensive_coins_package': True},\n",
       " 'can_edit_name': False,\n",
       " 'verified': True,\n",
       " 'new_modmail_exists': None,\n",
       " 'pref_autoplay': True,\n",
       " 'coins': 0,\n",
       " 'has_paypal_subscription': False,\n",
       " 'has_subscribed_to_premium': False,\n",
       " 'id': 'fn6gzhcl',\n",
       " 'has_stripe_subscription': False,\n",
       " 'oauth_client_id': '28v86Rmdy0t3zpLsABIlaw',\n",
       " 'can_create_subreddit': True,\n",
       " 'over_18': False,\n",
       " 'is_gold': False,\n",
       " 'is_mod': False,\n",
       " 'awarder_karma': 0,\n",
       " 'suspension_expiration_utc': None,\n",
       " 'has_verified_email': True,\n",
       " 'is_suspended': False,\n",
       " 'pref_video_autoplay': True,\n",
       " 'has_android_subscription': False,\n",
       " 'in_redesign_beta': True,\n",
       " 'icon_img': 'https://styles.redditmedia.com/t5_5ga0v8/styles/profileIcon_snoo7e1baabd-7daf-4774-a95d-92829e511322-headshot.png?width=256&amp;height=256&amp;crop=256:256,smart&amp;s=5bf6cac6695af43722caff15194db1958f1fc158',\n",
       " 'has_mod_mail': False,\n",
       " 'pref_nightmode': False,\n",
       " 'awardee_karma': 0,\n",
       " 'hide_from_robots': False,\n",
       " 'password_set': True,\n",
       " 'link_karma': 1,\n",
       " 'force_password_reset': False,\n",
       " 'total_karma': 1,\n",
       " 'seen_give_award_tooltip': False,\n",
       " 'inbox_count': 0,\n",
       " 'seen_premium_adblock_modal': False,\n",
       " 'pref_top_karma_subreddits': True,\n",
       " 'has_mail': False,\n",
       " 'pref_show_snoovatar': False,\n",
       " 'name': 'Rubinjo_L',\n",
       " 'pref_clickgadget': 5,\n",
       " 'created': 1638881905.0,\n",
       " 'gold_creddits': 0,\n",
       " 'created_utc': 1638881905.0,\n",
       " 'has_ios_subscription': False,\n",
       " 'pref_show_twitter': False,\n",
       " 'in_beta': False,\n",
       " 'comment_karma': 0,\n",
       " 'accept_followers': True,\n",
       " 'has_subscribed': True,\n",
       " 'linked_identities': [],\n",
       " 'seen_subreddit_chat_ftux': False}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from auth import CLIENT_ID, SECRET_KEY, REDDIT_USERNAME, REDDIT_PASSWORD\n",
    "\n",
    "import requests\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_KEY)\n",
    "\n",
    "data = {\n",
    "    \"grant_type\": \"password\",\n",
    "    \"username\": REDDIT_USERNAME,\n",
    "    \"password\": REDDIT_PASSWORD\n",
    "}\n",
    "\n",
    "headers = {\"User-Agent\": \"MyAPI/0.0.1\"}\n",
    "\n",
    "res = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth=auth, data=data, headers=headers)\n",
    "\n",
    "TOKEN = res.json()[\"access_token\"]\n",
    "\n",
    "headers[\"Authorization\"] = f'bearer {TOKEN}'\n",
    "\n",
    "requests.get(\"https://oauth.reddit.com/api/v1/me\", headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rr21pe in the wallstreetbets subreddit does not have enough comments.\n",
      "rr1ho7 in the Daytrading subreddit does not have enough comments.\n",
      "\n",
      "Top 3 subreddits used:\n",
      "wallstreetbets      5\n",
      "learnprogramming    5\n",
      "Daytrading          3\n",
      "Name: subreddit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Use company name, stock ticker and/or abbreviation of company\n",
    "SEARCH = [\"Apple\", \"AAPL\"]\n",
    "\n",
    "df_reddit = pd.DataFrame()\n",
    "\n",
    "for term in SEARCH:\n",
    "    payload = {\"q\": term, \"limit\": \"5\", \"sort\": \"new\"}\n",
    "\n",
    "    res = requests.get(\"https://oauth.reddit.com/r/subreddits/search\", headers=headers, params=payload)\n",
    "    for post in res.json()[\"data\"][\"children\"]:\n",
    "        df_reddit = df_reddit.append({\n",
    "            \"subreddit\": post[\"data\"][\"subreddit\"],\n",
    "            \"postid\": post[\"data\"][\"id\"],\n",
    "            \"text\": post[\"data\"][\"title\"] + \" \" + post[\"data\"][\"selftext\"],\n",
    "            \"created\": datetime.fromtimestamp(post[\"data\"][\"created\"])\n",
    "        }, ignore_index=True)\n",
    "\n",
    "df_reddit = df_reddit.drop_duplicates(\"postid\", ignore_index=True)\n",
    "\n",
    "for index, item in df_reddit.iterrows():\n",
    "    payload = {\"limit\": \"5\", \"sort\": \"new\"}\n",
    "\n",
    "    res = requests.get(\"https://oauth.reddit.com/r/\" + item[\"subreddit\"] + \"/comments/\" + item[\"postid\"], headers=headers, params=payload)\n",
    "    \n",
    "    for comment in res.json()[1][\"data\"][\"children\"]:\n",
    "        try:\n",
    "            df_reddit = df_reddit.append({\n",
    "                \"subreddit\": item[\"subreddit\"],\n",
    "                \"text\": comment[\"data\"][\"body\"],\n",
    "                \"created\": datetime.fromtimestamp(comment[\"data\"][\"created\"])\n",
    "            }, ignore_index=True)\n",
    "        except:\n",
    "            print(item[\"postid\"] + \" in the \" + item[\"subreddit\"] + \" subreddit does not have enough comments.\")\n",
    "        \n",
    "print(\"\\nTop 3 subreddits used:\")\n",
    "print(df_reddit[\"subreddit\"].value_counts()[:3])\n",
    "\n",
    "df_reddit = df_reddit.drop(columns=[\"subreddit\", \"postid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('https://api.twitter.com/2/tweets/search/recent', {'query': 'AAPL lang:en', 'max_results': 10, 'tweet.fields': 'id,text,author_id,created_at,lang,source', 'next_token': {}})\n",
      "Endpoint Response Code: 200\n"
     ]
    }
   ],
   "source": [
    "from auth import TWITTER_TOKEN\n",
    "\n",
    "#https://towardsdatascience.com/an-extensive-guide-to-collecting-tweets-from-twitter-api-v2-for-academic-research-using-python-3-518fcb71df2a\n",
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time\n",
    "\n",
    "def auth():\n",
    "    return TWITTER_TOKEN\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def create_url(keyword, max_results = 10):\n",
    "    \n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'max_results': max_results,\n",
    "                    'tweet.fields': 'id,text,author_id,created_at,lang,source',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "#Inputs for the request\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"AAPL lang:en\"\n",
    "max_results = 10\n",
    "\n",
    "url = create_url(keyword, max_results)\n",
    "print(url)\n",
    "json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "df_twitter_dirty = pd.DataFrame.from_dict(json_response[\"data\"])\n",
    "df_twitter_dirty = df_twitter_dirty.drop(columns=[\"author_id\", \"source\", \"lang\", \"id\"])\n",
    "\n",
    "df_twitter = pd.DataFrame()\n",
    "\n",
    "for index, item in df_twitter_dirty.iterrows():\n",
    "    df_twitter = df_twitter.append({\n",
    "                \"text\": item[\"text\"],\n",
    "                \"created\": datetime.fromisoformat(item[\"created_at\"].replace(\"Z\", \"\"))\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an anecdote about how i realized i donâ€™t have ...</td>\n",
       "      <td>2021-12-29 11:24:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do I sync a Strava workout from a non-Appl...</td>\n",
       "      <td>2021-12-29 11:23:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tofu Stinky And With Flaky Sugar Apples Butter...</td>\n",
       "      <td>2021-12-29 11:23:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recommendations for names-7wonders-Kingsburg-W...</td>\n",
       "      <td>2021-12-29 11:23:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need advice regarding my photos on new iPad. I...</td>\n",
       "      <td>2021-12-29 11:21:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apes, Let us band together for one last hurrah...</td>\n",
       "      <td>2021-12-29 08:10:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the problem with my code ? &amp;amp;#x200B...</td>\n",
       "      <td>2021-12-29 07:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Whats the best way to get an even out payout o...</td>\n",
       "      <td>2021-12-29 07:36:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PUT buy: AAPL 180P Exp 12/31 Looking at the 2h...</td>\n",
       "      <td>2021-12-29 06:58:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Testing a script $AAPL</td>\n",
       "      <td>2021-12-29 05:43:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             created\n",
       "0  an anecdote about how i realized i donâ€™t have ... 2021-12-29 11:24:53\n",
       "1  How do I sync a Strava workout from a non-Appl... 2021-12-29 11:23:50\n",
       "2  Tofu Stinky And With Flaky Sugar Apples Butter... 2021-12-29 11:23:49\n",
       "3  Recommendations for names-7wonders-Kingsburg-W... 2021-12-29 11:23:37\n",
       "4  Need advice regarding my photos on new iPad. I... 2021-12-29 11:21:22\n",
       "5  Apes, Let us band together for one last hurrah... 2021-12-29 08:10:10\n",
       "6  What is the problem with my code ? &amp;#x200B... 2021-12-29 07:38:00\n",
       "7  Whats the best way to get an even out payout o... 2021-12-29 07:36:18\n",
       "8  PUT buy: AAPL 180P Exp 12/31 Looking at the 2h... 2021-12-29 06:58:26\n",
       "9                            Testing a script $AAPL  2021-12-29 05:43:56"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_dirty = pd.concat([df_reddit, df_twitter], ignore_index=True)\n",
    "df_total_dirty.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 8, 4549, 75, 76, 276, 840, 276, 3590, 7178...</td>\n",
       "      <td>2021-12-29 11:24:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 76, 193, 276, 9885, 44, 0, 10422, 316, 44,...</td>\n",
       "      <td>2021-12-29 11:23:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 0, 8269, 15, 40, 11361, 3110, 7072, 3753, ...</td>\n",
       "      <td>2021-12-29 11:23:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2642, 177, 0, 7189, 8767, 8399, 7, 0, 9687...</td>\n",
       "      <td>2021-12-29 11:23:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 934, 4543, 6498, 317, 3065, 347, 114, 9823...</td>\n",
       "      <td>2021-12-29 11:21:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 5972, 7, 1419, 70, 1375, 392, 177, 23, 156...</td>\n",
       "      <td>2021-12-29 08:10:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 272, 38, 34, 1930, 40, 317, 12051, 1230, 6...</td>\n",
       "      <td>2021-12-29 07:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 272, 34, 150, 397, 36, 508, 8, 171, 640, 1...</td>\n",
       "      <td>2021-12-29 07:36:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 1583, 584, 821, 7130, 0, 7902, 0, 490, 313...</td>\n",
       "      <td>2021-12-29 06:58:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 5237, 44, 574, 5419, 7130, 2, 0, 0, 0, 0, ...</td>\n",
       "      <td>2021-12-29 05:43:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 3268, 3268, 8476, 2293, 3268, 3268, 7451, ...</td>\n",
       "      <td>2021-12-29 08:10:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 276, 109, 22, 36, 585, 1491, 34, 466, 60, ...</td>\n",
       "      <td>2021-12-29 10:16:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 11, 12, 8435, 60, 3224, 36, 450, 281, 276,...</td>\n",
       "      <td>2021-12-29 09:09:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 1086, 276, 7887, 225, 53, 43, 182, 430, 93...</td>\n",
       "      <td>2021-12-29 09:01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 34, 1930, 38, 11, 225, 273, 332, 508, 0, 4...</td>\n",
       "      <td>2021-12-29 11:03:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 8930, 0, 826, 78, 316, 768, 2, 0, 0, 0, 0,...</td>\n",
       "      <td>2021-12-29 08:39:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 230, 225, 0, 34, 517, 1230, 1073, 821, 34,...</td>\n",
       "      <td>2021-12-29 08:24:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 508, 34, 7081, 316, 34, 16469, 508, 4, 452...</td>\n",
       "      <td>2021-12-29 07:39:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 225, 7178, 4816, 64, 0, 769, 7452, 2381, 5...</td>\n",
       "      <td>2021-12-29 10:41:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2123, 34, 2375, 722, 543, 2995, 225, 1228,...</td>\n",
       "      <td>2021-12-29 08:04:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1, 11, 12, 18, 8333, 78, 190, 8333, 2, 0, 0, ...</td>\n",
       "      <td>2021-12-29 07:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1, 7071, 821, 8278, 7076, 60, 34, 7243, 67, 7...</td>\n",
       "      <td>2021-12-29 10:25:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1, 5419, 7130, 38, 1583, 0, 7178, 7243, 2272,...</td>\n",
       "      <td>2021-12-29 10:24:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1, 5419, 7130, 5419, 7133, 5419, 7149, 5419, ...</td>\n",
       "      <td>2021-12-29 10:23:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1, 7071, 821, 0, 60, 5855, 313, 0, 12, 1616, ...</td>\n",
       "      <td>2021-12-29 10:23:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[1, 7071, 821, 34, 0, 60, 4315, 313, 0, 12, 16...</td>\n",
       "      <td>2021-12-29 10:23:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[1, 7235, 10829, 132, 730, 0, 176, 36, 584, 44...</td>\n",
       "      <td>2021-12-29 10:22:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[1, 5419, 7130, 5419, 7993, 5419, 5721, 5419, ...</td>\n",
       "      <td>2021-12-29 10:22:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[1, 7604, 497, 6621, 64, 14042, 7178, 7243, 74...</td>\n",
       "      <td>2021-12-29 10:22:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[1, 7071, 821, 334, 7878, 277, 14158, 5419, 79...</td>\n",
       "      <td>2021-12-29 10:20:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[1, 7071, 821, 276, 230, 44, 648, 1748, 177, 0...</td>\n",
       "      <td>2021-12-29 10:17:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text             created\n",
       "0   [1, 8, 4549, 75, 76, 276, 840, 276, 3590, 7178... 2021-12-29 11:24:53\n",
       "1   [1, 76, 193, 276, 9885, 44, 0, 10422, 316, 44,... 2021-12-29 11:23:50\n",
       "2   [1, 0, 8269, 15, 40, 11361, 3110, 7072, 3753, ... 2021-12-29 11:23:49\n",
       "3   [1, 2642, 177, 0, 7189, 8767, 8399, 7, 0, 9687... 2021-12-29 11:23:37\n",
       "4   [1, 934, 4543, 6498, 317, 3065, 347, 114, 9823... 2021-12-29 11:21:22\n",
       "5   [1, 5972, 7, 1419, 70, 1375, 392, 177, 23, 156... 2021-12-29 08:10:10\n",
       "6   [1, 272, 38, 34, 1930, 40, 317, 12051, 1230, 6... 2021-12-29 07:38:00\n",
       "7   [1, 272, 34, 150, 397, 36, 508, 8, 171, 640, 1... 2021-12-29 07:36:18\n",
       "8   [1, 1583, 584, 821, 7130, 0, 7902, 0, 490, 313... 2021-12-29 06:58:26\n",
       "9   [1, 5237, 44, 574, 5419, 7130, 2, 0, 0, 0, 0, ... 2021-12-29 05:43:56\n",
       "10  [1, 3268, 3268, 8476, 2293, 3268, 3268, 7451, ... 2021-12-29 08:10:34\n",
       "11  [1, 276, 109, 22, 36, 585, 1491, 34, 466, 60, ... 2021-12-29 10:16:16\n",
       "12  [1, 11, 12, 8435, 60, 3224, 36, 450, 281, 276,... 2021-12-29 09:09:58\n",
       "13  [1, 1086, 276, 7887, 225, 53, 43, 182, 430, 93... 2021-12-29 09:01:07\n",
       "14  [1, 34, 1930, 38, 11, 225, 273, 332, 508, 0, 4... 2021-12-29 11:03:37\n",
       "15  [1, 8930, 0, 826, 78, 316, 768, 2, 0, 0, 0, 0,... 2021-12-29 08:39:12\n",
       "16  [1, 230, 225, 0, 34, 517, 1230, 1073, 821, 34,... 2021-12-29 08:24:48\n",
       "17  [1, 508, 34, 7081, 316, 34, 16469, 508, 4, 452... 2021-12-29 07:39:44\n",
       "18  [1, 225, 7178, 4816, 64, 0, 769, 7452, 2381, 5... 2021-12-29 10:41:21\n",
       "19  [1, 2123, 34, 2375, 722, 543, 2995, 225, 1228,... 2021-12-29 08:04:18\n",
       "20  [1, 11, 12, 18, 8333, 78, 190, 8333, 2, 0, 0, ... 2021-12-29 07:04:05\n",
       "21  [1, 7071, 821, 8278, 7076, 60, 34, 7243, 67, 7... 2021-12-29 10:25:57\n",
       "22  [1, 5419, 7130, 38, 1583, 0, 7178, 7243, 2272,... 2021-12-29 10:24:24\n",
       "23  [1, 5419, 7130, 5419, 7133, 5419, 7149, 5419, ... 2021-12-29 10:23:48\n",
       "24  [1, 7071, 821, 0, 60, 5855, 313, 0, 12, 1616, ... 2021-12-29 10:23:25\n",
       "25  [1, 7071, 821, 34, 0, 60, 4315, 313, 0, 12, 16... 2021-12-29 10:23:12\n",
       "26  [1, 7235, 10829, 132, 730, 0, 176, 36, 584, 44... 2021-12-29 10:22:32\n",
       "27  [1, 5419, 7130, 5419, 7993, 5419, 5721, 5419, ... 2021-12-29 10:22:23\n",
       "28  [1, 7604, 497, 6621, 64, 14042, 7178, 7243, 74... 2021-12-29 10:22:03\n",
       "29  [1, 7071, 821, 334, 7878, 277, 14158, 5419, 79... 2021-12-29 10:20:09\n",
       "30  [1, 7071, 821, 276, 230, 44, 648, 1748, 177, 0... 2021-12-29 10:17:18"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = pd.DataFrame()\n",
    "\n",
    "for index, item in df_total_dirty.iterrows():\n",
    "    df_total = df_total.append({\n",
    "        \"text\": encode_and_pad(tokenization(normalize_text(item[\"text\"])), SEQ_LENGTH),\n",
    "        \"created\": item[\"created\"]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "df_total.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7655dccab25508e2b7250356d0c4fb2b1981e06266edd0cc1bf19819e9b5c49e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
