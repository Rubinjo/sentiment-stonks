{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Packages\n",
    "Recommended to use [Anaconda](https://www.anaconda.com/l) in combination with an environment. Installation commands for all required packages can be found below. Choose the installation command that fits your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# With Anaconda with GPU\n",
    "!conda install ipykernel requests pandas numpy scikit-learn nltk matplotlib graphviz python-graphviz torchinfo pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "!pip install wget yfinance hiddenlayer\n",
    "\n",
    "# With Anaconda with CPU (no GPU support)\n",
    "# !conda install ipykernel requests pandas numpy scikit-learn nltk matplotlib graphviz python-graphviz pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "# !pip install wget yfinance hiddenlayer\n",
    "\n",
    "# Without Anaconda with GPU\n",
    "# !pip install wget yfinance hiddenlayer ipykernel requests pandas numpy scikit-learn nltk matplotlib graphviz torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "\n",
    "# Without Anaconda with CPU (no GPU support)\n",
    "# !pip install wget yfinance hiddenlayer ipykernel requests pandas numpy scikit-learn nltk matplotlib graphviz torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "Select and download datasets.  \n",
    "  \n",
    "All downloads are hosted on own Nextcloud server for consistently good performance. For dataset references please see links below.\n",
    "\n",
    "Available datasets:  \n",
    "[0](http://help.sentiment140.com/for-students) - 1,600,000 automatically labelled tweets.  \n",
    "[1](https://nlp.stanford.edu/sentiment/code.html) - 10,605 manually labelled Rotten Tomatoes reviews.  \n",
    "[2](https://ieee-dataport.org/open-access/stock-market-tweets-data#files) - 1,300 manually labelled financial tweets.  \n",
    "[3](https://arxiv.org/abs/1307.5336) - 4,840 manually labelled fiancial news headlines.  \n",
    "[4](https://github.com/ajayshewale/Sentiment-Analysis-of-Text-Data-Tweets-) - 5,970 manually labelled financial tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os\n",
    "\n",
    "# Select databases you want to use for training the model\n",
    "DATASETS_SELECTED = [1,2,3,4]\n",
    "\n",
    "all_urls = [\"https://nextcloud.lucashost.nl/s/QEDjzxCQidDZDR4/download/trainingandtestdata.zip\", \"https://nextcloud.lucashost.nl/s/e5tyPSHs9Lrc3bT/download/stanfordSentimentTreebank.zip\", \"https://nextcloud.lucashost.nl/s/bm8bqeKqdyFqiTe/download/tweets.zip\", \"https://nextcloud.lucashost.nl/s/2b4tNYKQp9jP7Bn/download/archive.zip\", \"https://nextcloud.lucashost.nl/s/tdC65kRGWzYzeP2/download/punkt.zip\"]\n",
    "urls = [all_urls[i] for i in DATASETS_SELECTED]\n",
    "path = \"datasets/\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "  os.makedirs(path)\n",
    "\n",
    "for url in urls:\n",
    "    split_url = url.split(\"/\")\n",
    "    if not (os.path.exists(path + split_url[-1])):\n",
    "      wget.download(url, out = path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(path + filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the differrent datasets and integrate them with eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23417</th>\n",
       "      <td>Ok ed let's do this, Zlatan, greizmann and Lap...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23418</th>\n",
       "      <td>Goal level: Zlatan  90k by Friday? = Posting e...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23419</th>\n",
       "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23420</th>\n",
       "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23421</th>\n",
       "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23422 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence Sentiment\n",
       "0      The Rock is destined to be the 21st Century 's...   neutral\n",
       "1      The gorgeously elaborate continuation of `` Th...   neutral\n",
       "2                         Effective but too-tepid biopic   neutral\n",
       "3      If you sometimes like to go to the movies to h...   neutral\n",
       "4      Emerges as something rare , an issue movie tha...  negative\n",
       "...                                                  ...       ...\n",
       "23417  Ok ed let's do this, Zlatan, greizmann and Lap...  positive\n",
       "23418  Goal level: Zlatan  90k by Friday? = Posting e...   neutral\n",
       "23419  @YouAreMyArsenal Wouldn't surprise me if we en...   neutral\n",
       "23420  Rib injury for Zlatan against Russia is a big ...   neutral\n",
       "23421  Noooooo! I was hoping to see Zlatan being Zlat...   neutral\n",
       "\n",
       "[23422 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in DATASETS_SELECTED:\n",
    "    if (i == 0):\n",
    "        df1_manual = pd.read_csv(path + \"testdata.manual.2009.06.14.csv\", names=['Sentiment', 'Sentence'], usecols=[0, 5])\n",
    "        df1_auto = pd.read_csv(path + \"training.1600000.processed.noemoticon.csv\", names=['Sentiment', 'Sentence'], usecols=[0, 5], encoding='ISO-8859-1')\n",
    "        df1 = df1_auto.append(df1_manual, ignore_index=True)\n",
    "        df1[\"Sentiment\"] = df1[\"Sentiment\"].apply(lambda sentiment: \"negative\" if sentiment == 0 else (\"neutral\" if sentiment == 2 else \"positive\"))\n",
    "        df = df.append(df1, ignore_index=True)\n",
    "    elif (i ==1):\n",
    "        df2_sentence = pd.read_csv(path + \"stanfordSentimentTreebank/datasetSentences.txt\", sep=\"\\t\")\n",
    "        df2_sentiment = pd.read_csv(path + \"stanfordSentimentTreebank/sentiment_labels.txt\", sep=\"|\")\n",
    "        df2 = pd.merge(df2_sentence, df2_sentiment, left_on=\"sentence_index\", right_on=\"phrase ids\")\n",
    "        df2 = df2.drop(columns=[\"sentence_index\", \"phrase ids\"])\n",
    "        df2 = df2.rename(columns={\"sentiment values\": \"Sentiment\", \"sentence\": \"Sentence\"})\n",
    "        df2[\"Sentiment\"] = df2[\"Sentiment\"].apply(lambda sentiment: \"negative\" if sentiment < 0.4 else (\"neutral\" if sentiment <= 0.6 else \"positive\"))\n",
    "        df = df.append(df2, ignore_index=True)\n",
    "    elif (i ==2):\n",
    "        df3 = pd.read_csv(path + \"tweets/tweets_labelled_09042020_16072020.csv\", sep=\";\", on_bad_lines=\"skip\")\n",
    "        df3 = df3.drop(columns=[\"id\", \"created_at\"])\n",
    "        df3 = df3.rename(columns={\"sentiment\": \"Sentiment\", \"text\": \"Sentence\"})\n",
    "        df3 = df3.dropna()\n",
    "        df = df.append(df3, ignore_index=True)\n",
    "    elif (i == 3):\n",
    "        df4 = pd.read_csv(path + 'all-data.csv', names=['Sentiment', 'Sentence'], encoding='ISO-8859-1')\n",
    "        df4['Sentiment'] = df4['Sentiment'].astype('string')\n",
    "        df4['Sentence'] = df4['Sentence'].astype('string')\n",
    "        df = df.append(df4, ignore_index=True)\n",
    "    elif (i == 4):\n",
    "        df5 = pd.read_csv(path + \"train.csv\")\n",
    "        df5 = df5.drop(columns=[\"Id\"])\n",
    "        df5 = df5.dropna()\n",
    "        df5 = df5[df5[\"Tweet\"] != \"Not Available\"]\n",
    "        df5 = df5[df5[\"Category\"] != \"Tweet\"]\n",
    "        df5 = df5.rename(columns={\"Category\": \"Sentiment\", \"Tweet\": \"Sentence\"})\n",
    "        df = df.append(df5, ignore_index=True)\n",
    "    else:\n",
    "        print(\"Database \" + str(i) + \" not found\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(sentence):\n",
    "    link_re_pattern = \"https?:\\/\\/t.co/[\\w]+\"\n",
    "    mention_re_pattern = \"@\\w+\"\n",
    "    enter_re_pattern = \"\\n\"\n",
    "    sentence = re.sub(link_re_pattern, \"\", sentence)\n",
    "    sentence = re.sub(mention_re_pattern, \"\", sentence)\n",
    "    sentence = re.sub(enter_re_pattern, \" \", sentence)\n",
    "    return sentence.lower()\n",
    "\n",
    "df[\"Sentence\"] = df[\"Sentence\"].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over- and/or undersample sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    8065\n",
       "positive    8065\n",
       "neutral     8065\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much you oversample compared to undersampling\n",
    "FACTOR = 0.5\n",
    "\n",
    "oversample_rate = math.floor((df[\"Sentiment\"].value_counts()[0] - df[\"Sentiment\"].value_counts()[-1]) * FACTOR)\n",
    "undersample_rate = math.ceil((df[\"Sentiment\"].value_counts()[0] - df[\"Sentiment\"].value_counts()[-1]) * (1 - FACTOR))\n",
    "\n",
    "most_df = df[df[\"Sentiment\"] == df[\"Sentiment\"].value_counts().index[0]]\n",
    "mid_df = df[df[\"Sentiment\"] == df[\"Sentiment\"].value_counts().index[1]]\n",
    "least_df = df[df[\"Sentiment\"] == df[\"Sentiment\"].value_counts().index[2]]\n",
    "\n",
    "drop_indices = np.random.choice(most_df.index, size=undersample_rate, replace=False)\n",
    "undersampled = most_df.drop(drop_indices, axis=0)\n",
    "oversampled = least_df.append(least_df.sample(oversample_rate, replace=True))\n",
    "\n",
    "midsample_rate = oversampled[\"Sentiment\"].value_counts()[0] - mid_df[\"Sentiment\"].value_counts()[0]\n",
    "\n",
    "if (midsample_rate < 0):\n",
    "    mid_drop_indices = np.random.choice(mid_df.index, -midsample_rate, replace=False)\n",
    "    midsampled = mid_df.drop(mid_drop_indices)\n",
    "else:\n",
    "    midsampled = mid_df.append(mid_df.sample(midsample_rate, replace=True))\n",
    "\n",
    "balanced_df = pd.concat([oversampled, midsampled, undersampled])\n",
    "balanced_df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem sentences with the Porter Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "USE_STEMMER = True\n",
    "\n",
    "porter_stemmer  = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r'[\\w\\d\\']+(?![^\\s,.\\\"])')\n",
    "\n",
    "def tokenization(sentence):\n",
    "    sentence = tokenizer.tokenize(sentence)\n",
    "    for idx, word in enumerate(sentence):\n",
    "        if (USE_STEMMER):\n",
    "            sentence[idx] = porter_stemmer.stem(word)\n",
    "        else:\n",
    "            sentence[idx] = word\n",
    "    return sentence\n",
    "\n",
    "balanced_df[\"Sentence\"] = balanced_df[\"Sentence\"].apply(tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoded sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<SOS>', '<EOS>', 'emerg', 'as', 'someth', 'rare', 'an', 'issu', 'movi', 'that', \"'s\", 'so', 'honest', 'and', 'keenli', 'observ', 'it', 'doe', \"n't\", 'feel', 'like', 'one', 'perhap', 'no', 'pictur', 'ever', 'made', 'ha', 'more', 'liter', 'show', 'the', 'road', 'to', 'hell', 'is', 'pave', 'with', 'good', 'intent', 'thi', 'a', 'film', 'well', 'worth', 'see', 'talk', 'sing', 'head']\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "\n",
    "for index, row in balanced_df.iterrows():\n",
    "    for token in row[\"Sentence\"]:\n",
    "        if token not in index2word:\n",
    "                index2word.append(token)\n",
    "\n",
    "word2index = {token: idx for idx, token in enumerate(index2word)}\n",
    "print(list(islice(word2index, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_map(sentiment):\n",
    "    if sentiment == \"negative\":\n",
    "        return 0\n",
    "    elif sentiment == \"neutral\":\n",
    "        return 1\n",
    "    else: #positive\n",
    "        return 2\n",
    "\n",
    "def encode_and_pad(sentence, length):\n",
    "    sos = [word2index[\"<SOS>\"]]\n",
    "    eos = [word2index[\"<EOS>\"]]\n",
    "    pad = [word2index[\"<PAD>\"]]\n",
    "    encoded = []\n",
    "\n",
    "    if len(sentence) < length - 2: # -2 for SOS and EOS\n",
    "        n_pads = length - 2 - len(sentence)\n",
    "        for w in sentence:\n",
    "            try:\n",
    "                encoded.append(word2index[w])\n",
    "            except:\n",
    "                encoded.append(word2index[\"<PAD>\"])\n",
    "        # encoded = [word2index[w] for w in sentence]\n",
    "        return sos + encoded + eos + pad * n_pads \n",
    "    else: # sentence is longer than possible; truncating\n",
    "        for w in sentence:\n",
    "            try:\n",
    "                encoded.append(word2index[w])\n",
    "            except:\n",
    "                encoded.append(word2index[\"<PAD>\"])\n",
    "        # encoded = [word2index[w] for w in sentence]\n",
    "        truncated = encoded[:length - 2]\n",
    "        return sos + truncated + eos\n",
    "\n",
    "SEQ_LENGTH = 32\n",
    "\n",
    "encoded = [(encode_and_pad(row[\"Sentence\"], SEQ_LENGTH), sentiment_map(row[\"Sentiment\"])) for index, row in balanced_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "TEST_SIZE = 0.15\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "train_encoded, test_encoded = train_test_split(encoded, test_size=TEST_SIZE)\n",
    "\n",
    "train_x = np.array([sentence for sentence, sentiment in train_encoded])\n",
    "train_y = np.array([sentiment for sentence, sentiment in train_encoded])\n",
    "test_x = np.array([sentence for sentence, sentiment in test_encoded])\n",
    "test_y = np.array([sentiment for sentence, sentiment in test_encoded])\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# drop_last is used to drop the final batch if does not have BATCH_SIZE elements\n",
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_dl = DataLoader(test_ds, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "Create a LSTM neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LSTM_Sentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout1, dropout2, dropout3):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Input: 1x32\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # Output: 64x32\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout1)\n",
    "        # Output: 32x32\n",
    "        self.conv = nn.Conv1d(32, 16, 5)\n",
    "        # Output: 16x28\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout2 = nn.Dropout(dropout2)\n",
    "        # Output: 16x14\n",
    "        self.fc1 = nn.Linear(16 * 14, 64)\n",
    "        self.dropout3 = nn.Dropout(dropout3)\n",
    "        # Output: 64\n",
    "        self.fc2 = nn.Linear(64, 3)\n",
    "        # Output: 3\n",
    "    def forward(self, x, hidden):\n",
    "        embs = self.embedding(x)\n",
    "        out, hidden = self.lstm(embs, hidden)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.conv(out)\n",
    "        out = self.pool(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout3(out)\n",
    "        out = self.fc2(out)\n",
    "        return out, hidden\n",
    "    def init_hidden(self, batch=BATCH_SIZE):\n",
    "        return (torch.zeros(self.num_layers, batch, self.hidden_dim), torch.zeros(self.num_layers, batch, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Sentiment(\n",
      "  (embedding): Embedding(21249, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 32, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (conv): Conv1d(32, 16, kernel_size=(5,), stride=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=224, out_features=64, bias=True)\n",
      "  (dropout3): Dropout(p=0.4, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "model = LSTM_Sentiment(len(word2index), 64, 32, 1, 0.1, 0.2, 0.4)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(dot.exe:18864): Pango-WARNING **: couldn't load font \"Times Not-Rotated 10\", falling back to \"Sans Not-Rotated 10\", expect ugly output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 32])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n -->\r\n<!-- Title: %3 Pages: 1 -->\r\n<svg width=\"1549pt\" height=\"702pt\"\r\n viewBox=\"0.00 0.00 1549.00 702.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 666)\">\r\n<title>%3</title>\r\n<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-666 1477,-666 1477,36 -72,36\"/>\r\n<!-- /outputs/14 -->\r\n<g id=\"node1\" class=\"node\"><title>/outputs/14</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"144,-576 90,-576 90,-540 144,-540 144,-576\"/>\r\n<text text-anchor=\"start\" x=\"100\" y=\"-555\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\r\n</g>\r\n<!-- /outputs/15 -->\r\n<g id=\"node2\" class=\"node\"><title>/outputs/15</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"257,-576 191,-576 191,-540 257,-540 257,-576\"/>\r\n<text text-anchor=\"start\" x=\"199\" y=\"-555\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Transpose</text>\r\n</g>\r\n<!-- /outputs/14&#45;&gt;/outputs/15 -->\r\n<g id=\"edge1\" class=\"edge\"><title>/outputs/14&#45;&gt;/outputs/15</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.225,-558C155.235,-558 168.321,-558 180.635,-558\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.734,-561.5 190.734,-558 180.734,-554.5 180.734,-561.5\"/>\r\n</g>\r\n<!-- /outputs/37/38/39 -->\r\n<g id=\"node21\" class=\"node\"><title>/outputs/37/38/39</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"358,-468 304,-468 304,-432 358,-432 358,-468\"/>\r\n<text text-anchor=\"start\" x=\"318\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">LSTM</text>\r\n</g>\r\n<!-- /outputs/15&#45;&gt;/outputs/37/38/39 -->\r\n<g id=\"edge2\" class=\"edge\"><title>/outputs/15&#45;&gt;/outputs/37/38/39</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M256.944,-539.772C260.827,-537.035 264.612,-534.088 268,-531 285.449,-515.097 301.538,-493.791 312.952,-477.022\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"316.171,-478.502 318.791,-468.236 310.341,-474.628 316.171,-478.502\"/>\r\n</g>\r\n<!-- /outputs/16 -->\r\n<g id=\"node3\" class=\"node\"><title>/outputs/16</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"268,-522 180,-522 180,-486 268,-486 268,-522\"/>\r\n<text text-anchor=\"start\" x=\"188\" y=\"-501\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">prim::Constant</text>\r\n</g>\r\n<!-- /outputs/16&#45;&gt;/outputs/37/38/39 -->\r\n<g id=\"edge3\" class=\"edge\"><title>/outputs/16&#45;&gt;/outputs/37/38/39</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M260.256,-485.869C271.426,-480.124 283.769,-473.776 294.927,-468.038\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.677,-471.073 303.969,-463.387 293.475,-464.848 296.677,-471.073\"/>\r\n</g>\r\n<!-- /outputs/17 -->\r\n<g id=\"node4\" class=\"node\"><title>/outputs/17</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-630 0,-630 0,-594 54,-594 54,-630\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-609\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/20 -->\r\n<g id=\"node7\" class=\"node\"><title>/outputs/20</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"144,-522 90,-522 90,-486 144,-486 144,-522\"/>\r\n<text text-anchor=\"start\" x=\"100\" y=\"-501\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\r\n</g>\r\n<!-- /outputs/17&#45;&gt;/outputs/20 -->\r\n<g id=\"edge4\" class=\"edge\"><title>/outputs/17&#45;&gt;/outputs/20</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M46.3562,-593.808C49.0066,-590.936 51.6347,-587.941 54,-585 72.0758,-562.522 71.9242,-553.478 90,-531 90.2957,-530.632 90.5954,-530.264 90.8988,-529.895\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.6893,-532.021 97.6438,-522.192 88.4229,-527.41 93.6893,-532.021\"/>\r\n</g>\r\n<!-- /outputs/18 -->\r\n<g id=\"node5\" class=\"node\"><title>/outputs/18</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-576 0,-576 0,-540 54,-540 54,-576\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-555\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/18&#45;&gt;/outputs/20 -->\r\n<g id=\"edge5\" class=\"edge\"><title>/outputs/18&#45;&gt;/outputs/20</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-541.798C62.8323,-536.626 72.2933,-530.82 81.2235,-525.34\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.2263,-528.218 89.919,-520.004 79.5652,-522.251 83.2263,-528.218\"/>\r\n</g>\r\n<!-- /outputs/19 -->\r\n<g id=\"node6\" class=\"node\"><title>/outputs/19</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-522 0,-522 0,-486 54,-486 54,-522\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-501\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/19&#45;&gt;/outputs/20 -->\r\n<g id=\"edge6\" class=\"edge\"><title>/outputs/19&#45;&gt;/outputs/20</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-504C62.3932,-504 71.3106,-504 79.8241,-504\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.919,-507.5 89.919,-504 79.919,-500.5 79.919,-507.5\"/>\r\n</g>\r\n<!-- /outputs/34 -->\r\n<g id=\"node18\" class=\"node\"><title>/outputs/34</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"259.5,-468 188.5,-468 188.5,-432 259.5,-432 259.5,-468\"/>\r\n<text text-anchor=\"start\" x=\"197\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\r\n</g>\r\n<!-- /outputs/20&#45;&gt;/outputs/34 -->\r\n<g id=\"edge7\" class=\"edge\"><title>/outputs/20&#45;&gt;/outputs/34</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.225,-490.513C154.874,-485.036 167.466,-478.56 179.422,-472.411\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"181.106,-475.481 188.399,-467.795 177.905,-469.256 181.106,-475.481\"/>\r\n</g>\r\n<!-- /outputs/21 -->\r\n<g id=\"node8\" class=\"node\"><title>/outputs/21</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-468 0,-468 0,-432 54,-432 54,-468\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/24 -->\r\n<g id=\"node11\" class=\"node\"><title>/outputs/24</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"144,-414 90,-414 90,-378 144,-378 144,-414\"/>\r\n<text text-anchor=\"start\" x=\"100\" y=\"-393\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\r\n</g>\r\n<!-- /outputs/21&#45;&gt;/outputs/24 -->\r\n<g id=\"edge8\" class=\"edge\"><title>/outputs/21&#45;&gt;/outputs/24</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-433.798C62.8323,-428.626 72.2933,-422.82 81.2235,-417.34\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.2263,-420.218 89.919,-412.004 79.5652,-414.251 83.2263,-420.218\"/>\r\n</g>\r\n<!-- /outputs/22 -->\r\n<g id=\"node9\" class=\"node\"><title>/outputs/22</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-414 0,-414 0,-378 54,-378 54,-414\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-393\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/22&#45;&gt;/outputs/24 -->\r\n<g id=\"edge9\" class=\"edge\"><title>/outputs/22&#45;&gt;/outputs/24</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-396C62.3932,-396 71.3106,-396 79.8241,-396\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.919,-399.5 89.919,-396 79.919,-392.5 79.919,-399.5\"/>\r\n</g>\r\n<!-- /outputs/23 -->\r\n<g id=\"node10\" class=\"node\"><title>/outputs/23</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-360 0,-360 0,-324 54,-324 54,-360\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-339\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/23&#45;&gt;/outputs/24 -->\r\n<g id=\"edge10\" class=\"edge\"><title>/outputs/23&#45;&gt;/outputs/24</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-358.202C62.8323,-363.374 72.2933,-369.18 81.2235,-374.66\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.5652,-377.749 89.919,-379.996 83.2263,-371.782 79.5652,-377.749\"/>\r\n</g>\r\n<!-- /outputs/35 -->\r\n<g id=\"node19\" class=\"node\"><title>/outputs/35</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"259.5,-414 188.5,-414 188.5,-378 259.5,-378 259.5,-414\"/>\r\n<text text-anchor=\"start\" x=\"197\" y=\"-393\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\r\n</g>\r\n<!-- /outputs/24&#45;&gt;/outputs/35 -->\r\n<g id=\"edge11\" class=\"edge\"><title>/outputs/24&#45;&gt;/outputs/35</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.225,-396C154.561,-396 166.727,-396 178.366,-396\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.399,-399.5 188.399,-396 178.399,-392.5 178.399,-399.5\"/>\r\n</g>\r\n<!-- /outputs/25 -->\r\n<g id=\"node12\" class=\"node\"><title>/outputs/25</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-306 0,-306 0,-270 54,-270 54,-306\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-285\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- 18002773273363441372 -->\r\n<g id=\"node33\" class=\"node\"><title>18002773273363441372</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"144,-202 90,-202 90,-158 144,-158 144,-202\"/>\r\n<text text-anchor=\"start\" x=\"100\" y=\"-186\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\r\n<text text-anchor=\"start\" x=\"126\" y=\"-165\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x3</text>\r\n</g>\r\n<!-- /outputs/25&#45;&gt;18002773273363441372 -->\r\n<g id=\"edge29\" class=\"edge\"><title>/outputs/25&#45;&gt;18002773273363441372</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M45.9096,-269.962C48.675,-267.018 51.4551,-263.961 54,-261 67.9266,-244.795 82.498,-225.872 94.0129,-210.393\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.9476,-212.311 100.072,-202.187 91.3164,-208.153 96.9476,-212.311\"/>\r\n</g>\r\n<!-- /outputs/26 -->\r\n<g id=\"node13\" class=\"node\"><title>/outputs/26</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-252 0,-252 0,-216 54,-216 54,-252\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-231\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/26&#45;&gt;18002773273363441372 -->\r\n<g id=\"edge30\" class=\"edge\"><title>/outputs/26&#45;&gt;18002773273363441372</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-217.798C62.8323,-212.626 72.2933,-206.82 81.2235,-201.34\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.2263,-204.218 89.919,-196.004 79.5652,-198.251 83.2263,-204.218\"/>\r\n</g>\r\n<!-- /outputs/27 -->\r\n<g id=\"node14\" class=\"node\"><title>/outputs/27</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-198 0,-198 0,-162 54,-162 54,-198\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-177\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/27&#45;&gt;18002773273363441372 -->\r\n<g id=\"edge31\" class=\"edge\"><title>/outputs/27&#45;&gt;18002773273363441372</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-180C62.3932,-180 71.3106,-180 79.8241,-180\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.919,-183.5 89.919,-180 79.919,-176.5 79.919,-183.5\"/>\r\n</g>\r\n<!-- /outputs/29 -->\r\n<g id=\"node15\" class=\"node\"><title>/outputs/29</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-144 0,-144 0,-108 54,-108 54,-144\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-123\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/29&#45;&gt;18002773273363441372 -->\r\n<g id=\"edge26\" class=\"edge\"><title>/outputs/29&#45;&gt;18002773273363441372</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4029,-142.202C62.8323,-147.374 72.2933,-153.18 81.2235,-158.66\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.5652,-161.749 89.919,-163.996 83.2263,-155.782 79.5652,-161.749\"/>\r\n</g>\r\n<!-- /outputs/30 -->\r\n<g id=\"node16\" class=\"node\"><title>/outputs/30</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-90 0,-90 0,-54 54,-54 54,-90\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/30&#45;&gt;18002773273363441372 -->\r\n<g id=\"edge27\" class=\"edge\"><title>/outputs/30&#45;&gt;18002773273363441372</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M45.9096,-90.0383C48.675,-92.9824 51.4551,-96.0388 54,-99 67.9266,-115.205 82.498,-134.128 94.0129,-149.607\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.3164,-151.847 100.072,-157.813 96.9476,-147.689 91.3164,-151.847\"/>\r\n</g>\r\n<!-- /outputs/31 -->\r\n<g id=\"node17\" class=\"node\"><title>/outputs/31</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-36 0,-36 0,-0 54,-0 54,-36\"/>\r\n<text text-anchor=\"start\" x=\"16\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Slice</text>\r\n</g>\r\n<!-- /outputs/31&#45;&gt;18002773273363441372 -->\r\n<g id=\"edge28\" class=\"edge\"><title>/outputs/31&#45;&gt;18002773273363441372</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M47.0523,-36.1765C49.5477,-39.0038 51.9467,-41.9893 54,-45 76.3579,-77.7838 94.2365,-119.925 104.944,-148.333\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"101.681,-149.602 108.428,-157.771 108.248,-147.178 101.681,-149.602\"/>\r\n</g>\r\n<!-- /outputs/34&#45;&gt;/outputs/37/38/39 -->\r\n<g id=\"edge12\" class=\"edge\"><title>/outputs/34&#45;&gt;/outputs/37/38/39</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M259.672,-450C270.536,-450 282.556,-450 293.54,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"293.682,-453.5 303.682,-450 293.682,-446.5 293.682,-453.5\"/>\r\n</g>\r\n<!-- /outputs/35&#45;&gt;/outputs/37/38/39 -->\r\n<g id=\"edge13\" class=\"edge\"><title>/outputs/35&#45;&gt;/outputs/37/38/39</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M259.672,-413.831C270.872,-419.591 283.301,-425.983 294.556,-431.772\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"293.188,-435.004 303.682,-436.465 296.39,-428.779 293.188,-435.004\"/>\r\n</g>\r\n<!-- /outputs/36 -->\r\n<g id=\"node20\" class=\"node\"><title>/outputs/36</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"259.5,-279 188.5,-279 188.5,-243 259.5,-243 259.5,-279\"/>\r\n<text text-anchor=\"start\" x=\"197\" y=\"-258\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\r\n</g>\r\n<!-- /outputs/36&#45;&gt;/outputs/37/38/39 -->\r\n<g id=\"edge14\" class=\"edge\"><title>/outputs/36&#45;&gt;/outputs/37/38/39</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M235.068,-279.122C253.57,-312.425 293.072,-383.529 314.835,-422.704\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.047,-424.891 319.963,-431.933 318.166,-421.491 312.047,-424.891\"/>\r\n</g>\r\n<!-- /outputs/40 -->\r\n<g id=\"node22\" class=\"node\"><title>/outputs/40</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"453,-468 394,-468 394,-432 453,-432 453,-468\"/>\r\n<text text-anchor=\"start\" x=\"402.5\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Squeeze</text>\r\n</g>\r\n<!-- /outputs/37/38/39&#45;&gt;/outputs/40 -->\r\n<g id=\"edge15\" class=\"edge\"><title>/outputs/37/38/39&#45;&gt;/outputs/40</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M358.176,-450C366.119,-450 375.02,-450 383.61,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"383.848,-453.5 393.848,-450 383.848,-446.5 383.848,-453.5\"/>\r\n</g>\r\n<!-- /outputs/41 -->\r\n<g id=\"node23\" class=\"node\"><title>/outputs/41</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"555,-468 489,-468 489,-432 555,-432 555,-468\"/>\r\n<text text-anchor=\"start\" x=\"497\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Transpose</text>\r\n</g>\r\n<!-- /outputs/40&#45;&gt;/outputs/41 -->\r\n<g id=\"edge16\" class=\"edge\"><title>/outputs/40&#45;&gt;/outputs/41</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M453.192,-450C461.171,-450 470.008,-450 478.595,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.87,-453.5 488.87,-450 478.87,-446.5 478.87,-453.5\"/>\r\n</g>\r\n<!-- /outputs/42/43 -->\r\n<g id=\"node24\" class=\"node\"><title>/outputs/42/43</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"647,-468 591,-468 591,-432 647,-432 647,-468\"/>\r\n<text text-anchor=\"start\" x=\"599\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Dropout</text>\r\n</g>\r\n<!-- /outputs/41&#45;&gt;/outputs/42/43 -->\r\n<g id=\"edge17\" class=\"edge\"><title>/outputs/41&#45;&gt;/outputs/42/43</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M555.163,-450C563.429,-450 572.389,-450 580.883,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"580.936,-453.5 590.936,-450 580.936,-446.5 580.936,-453.5\"/>\r\n</g>\r\n<!-- /outputs/44 -->\r\n<g id=\"node25\" class=\"node\"><title>/outputs/44</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"737,-468 683,-468 683,-432 737,-432 737,-468\"/>\r\n<text text-anchor=\"start\" x=\"695\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv5</text>\r\n</g>\r\n<!-- /outputs/42/43&#45;&gt;/outputs/44 -->\r\n<g id=\"edge18\" class=\"edge\"><title>/outputs/42/43&#45;&gt;/outputs/44</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M647.187,-450C655.255,-450 664.222,-450 672.768,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"672.895,-453.5 682.895,-450 672.895,-446.5 672.895,-453.5\"/>\r\n</g>\r\n<!-- /outputs/45 -->\r\n<g id=\"node26\" class=\"node\"><title>/outputs/45</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"835,-468 773,-468 773,-432 835,-432 835,-468\"/>\r\n<text text-anchor=\"start\" x=\"781\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2</text>\r\n</g>\r\n<!-- /outputs/44&#45;&gt;/outputs/45 -->\r\n<g id=\"edge19\" class=\"edge\"><title>/outputs/44&#45;&gt;/outputs/45</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M737.117,-450C745.136,-450 754.152,-450 762.881,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"762.92,-453.5 772.92,-450 762.919,-446.5 762.92,-453.5\"/>\r\n</g>\r\n<!-- /outputs/46 -->\r\n<g id=\"node27\" class=\"node\"><title>/outputs/46</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"925,-468 871,-468 871,-432 925,-432 925,-468\"/>\r\n<text text-anchor=\"start\" x=\"888\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Relu</text>\r\n</g>\r\n<!-- /outputs/45&#45;&gt;/outputs/46 -->\r\n<g id=\"edge20\" class=\"edge\"><title>/outputs/45&#45;&gt;/outputs/46</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M835.124,-450C843.321,-450 852.283,-450 860.78,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"860.829,-453.5 870.829,-450 860.829,-446.5 860.829,-453.5\"/>\r\n</g>\r\n<!-- /outputs/47/48 -->\r\n<g id=\"node28\" class=\"node\"><title>/outputs/47/48</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1017,-468 961,-468 961,-432 1017,-432 1017,-468\"/>\r\n<text text-anchor=\"start\" x=\"969\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Dropout</text>\r\n</g>\r\n<!-- /outputs/46&#45;&gt;/outputs/47/48 -->\r\n<g id=\"edge21\" class=\"edge\"><title>/outputs/46&#45;&gt;/outputs/47/48</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M925.222,-450C933.168,-450 942.057,-450 950.588,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"950.73,-453.5 960.73,-450 950.73,-446.5 950.73,-453.5\"/>\r\n</g>\r\n<!-- /outputs/49 -->\r\n<g id=\"node29\" class=\"node\"><title>/outputs/49</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1107,-468 1053,-468 1053,-432 1107,-432 1107,-468\"/>\r\n<text text-anchor=\"start\" x=\"1063\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Flatten</text>\r\n</g>\r\n<!-- /outputs/47/48&#45;&gt;/outputs/49 -->\r\n<g id=\"edge22\" class=\"edge\"><title>/outputs/47/48&#45;&gt;/outputs/49</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M1017.19,-450C1025.25,-450 1034.22,-450 1042.77,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1042.89,-453.5 1052.89,-450 1042.89,-446.5 1042.89,-453.5\"/>\r\n</g>\r\n<!-- 10871242753685598830 -->\r\n<g id=\"node32\" class=\"node\"><title>10871242753685598830</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1223,-468 1143,-468 1143,-432 1223,-432 1223,-468\"/>\r\n<text text-anchor=\"start\" x=\"1151\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\r\n</g>\r\n<!-- /outputs/49&#45;&gt;10871242753685598830 -->\r\n<g id=\"edge24\" class=\"edge\"><title>/outputs/49&#45;&gt;10871242753685598830</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M1107.01,-450C1114.82,-450 1123.67,-450 1132.48,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1132.73,-453.5 1142.73,-450 1132.73,-446.5 1132.73,-453.5\"/>\r\n</g>\r\n<!-- /outputs/52/53 -->\r\n<g id=\"node30\" class=\"node\"><title>/outputs/52/53</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1315,-468 1259,-468 1259,-432 1315,-432 1315,-468\"/>\r\n<text text-anchor=\"start\" x=\"1267\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Dropout</text>\r\n</g>\r\n<!-- /outputs/54 -->\r\n<g id=\"node31\" class=\"node\"><title>/outputs/54</title>\r\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"1405,-468 1351,-468 1351,-432 1405,-432 1405,-468\"/>\r\n<text text-anchor=\"start\" x=\"1363\" y=\"-447\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\r\n</g>\r\n<!-- /outputs/52/53&#45;&gt;/outputs/54 -->\r\n<g id=\"edge23\" class=\"edge\"><title>/outputs/52/53&#45;&gt;/outputs/54</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M1315.19,-450C1323.25,-450 1332.22,-450 1340.77,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1340.89,-453.5 1350.89,-450 1340.89,-446.5 1340.89,-453.5\"/>\r\n</g>\r\n<!-- 10871242753685598830&#45;&gt;/outputs/52/53 -->\r\n<g id=\"edge25\" class=\"edge\"><title>10871242753685598830&#45;&gt;/outputs/52/53</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M1223.14,-450C1231.52,-450 1240.34,-450 1248.65,-450\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1248.82,-453.5 1258.82,-450 1248.82,-446.5 1248.82,-453.5\"/>\r\n</g>\r\n<!-- 18002773273363441372&#45;&gt;/outputs/36 -->\r\n<g id=\"edge32\" class=\"edge\"><title>18002773273363441372&#45;&gt;/outputs/36</title>\r\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.225,-200.231C158.576,-211.301 176.455,-225.094 191.551,-236.739\"/>\r\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.556,-239.621 199.612,-242.957 193.831,-234.078 189.556,-239.621\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n",
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x218df31cc10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "hl.build_graph(model, (torch.zeros([50, 32]).to(device).long(), (torch.zeros(1, 50, 32).to(device), torch.zeros(1, 50, 32).to(device))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the LSTM neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 32])\n",
      "epoch: 0, batch: 0  /411, time: 0.011s, loss: 1.096, acc: 0.420\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "epoch: 0, batch: 103/411, time: 0.666s, loss: 1.099, acc: 0.320\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "epoch: 0, batch: 206/411, time: 1.277s, loss: 1.103, acc: 0.300\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "epoch: 0, batch: 309/411, time: 1.879s, loss: 1.096, acc: 0.420\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "Accuracy on the test set: 0.394\n",
      "torch.Size([50, 32])\n",
      "epoch: 1, batch: 0  /411, time: 2.651s, loss: 1.085, acc: 0.420\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "epoch: 1, batch: 103/411, time: 3.267s, loss: 1.076, acc: 0.500\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "epoch: 1, batch: 206/411, time: 3.895s, loss: 1.076, acc: 0.360\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n",
      "torch.Size([50, 32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RUBENL~1\\AppData\\Local\\Temp/ipykernel_14576/2966738237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\miniconda3\\envs\\stonks\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\RUBENL~1\\AppData\\Local\\Temp/ipykernel_14576/2756582301.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\miniconda3\\envs\\stonks\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\miniconda3\\envs\\stonks\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\miniconda3\\envs\\stonks\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[1;34m\"but got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "start=time.time()\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    h0, c0 =  model.init_hidden()\n",
    "\n",
    "    h0 = h0.to(device)\n",
    "    c0 = c0.to(device)\n",
    "\n",
    "    # Train mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dl):\n",
    "\n",
    "        input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            out, hidden = model(input, (h0, c0))\n",
    "            train_loss = criterion(out, target.long())\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "        correct = torch.sum(torch.eq(pred, target)).item()\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        if not batch_idx % (math.ceil(len(train_dl) / 4)):\n",
    "            print(f'epoch: {epoch}, batch: {batch_idx:<{len(str(len(train_dl)))}}/{len(train_dl)}, time: {elapsed:.3f}s, loss: {train_loss.item():.3f}, acc: {correct / BATCH_SIZE:.3f}')\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    batch_acc = []\n",
    "    for batch_idx, batch in enumerate(test_dl):\n",
    "\n",
    "        input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(False):\n",
    "            out, hidden = model(input, (h0, c0))\n",
    "            _, preds = torch.max(out, 1)\n",
    "            preds = preds.to(device).tolist()\n",
    "            batch_acc.append(accuracy_score(preds, target.tolist()))\n",
    "\n",
    "            test_loss = criterion(out, target.long())\n",
    "\n",
    "    print(f'Accuracy on the test set: {sum(batch_acc)/len(batch_acc):.3f}')\n",
    "\n",
    "    test_losses.append(test_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Save the trained model.  \n",
    "Skip if you don't wish to save your lastly trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"model/\"\n",
    "if not os.path.exists(path):\n",
    "  os.makedirs(path)\n",
    "\n",
    "torch.save(model.state_dict(), path + \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "Load the saved model from `./model/model.pth`.  \n",
    "Skip if you don't wish to load the lastly saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_Sentiment(\n",
       "  (embedding): Embedding(8516, 64, padding_idx=0)\n",
       "  (lstm): LSTM(64, 32, batch_first=True)\n",
       "  (conv): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=240, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"model/\"\n",
    "model = LSTM_Sentiment(len(word2index), 64, 32, 1, 0.2)\n",
    "model.load_state_dict(torch.load(path + \"model.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(test_losses, label=\"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on the test set: 0.673\n"
     ]
    }
   ],
   "source": [
    "batch_acc = []\n",
    "for batch_idx, batch in enumerate(test_dl):\n",
    "\n",
    "    input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        out, hidden = model(input, (h0, c0))\n",
    "        _, preds = torch.max(out, 1)\n",
    "        preds = preds.to(device).tolist()\n",
    "        batch_acc.append(accuracy_score(preds, target.tolist()))\n",
    "\n",
    "print(f'Final accuracy on the test set: {sum(batch_acc)/len(batch_acc):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit API\n",
    "\n",
    "Get Reddit posts and comments that corrospond to given keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_employee': False,\n",
       " 'seen_layout_switch': False,\n",
       " 'has_visited_new_profile': False,\n",
       " 'pref_no_profanity': True,\n",
       " 'has_external_account': False,\n",
       " 'pref_geopopular': '',\n",
       " 'seen_redesign_modal': False,\n",
       " 'pref_show_trending': True,\n",
       " 'subreddit': {'default_set': True,\n",
       "  'user_is_contributor': False,\n",
       "  'banner_img': '',\n",
       "  'restrict_posting': True,\n",
       "  'user_is_banned': False,\n",
       "  'free_form_reports': True,\n",
       "  'community_icon': None,\n",
       "  'show_media': True,\n",
       "  'icon_color': '',\n",
       "  'user_is_muted': False,\n",
       "  'display_name': 'u_Rubinjo_L',\n",
       "  'header_img': None,\n",
       "  'title': '',\n",
       "  'coins': 0,\n",
       "  'previous_names': [],\n",
       "  'over_18': False,\n",
       "  'icon_size': [256, 256],\n",
       "  'primary_color': '',\n",
       "  'icon_img': 'https://styles.redditmedia.com/t5_5ga0v8/styles/profileIcon_snoo7e1baabd-7daf-4774-a95d-92829e511322-headshot.png?width=256&amp;height=256&amp;crop=256:256,smart&amp;s=5bf6cac6695af43722caff15194db1958f1fc158',\n",
       "  'description': '',\n",
       "  'submit_link_label': '',\n",
       "  'header_size': None,\n",
       "  'restrict_commenting': False,\n",
       "  'subscribers': 0,\n",
       "  'submit_text_label': '',\n",
       "  'is_default_icon': False,\n",
       "  'link_flair_position': '',\n",
       "  'display_name_prefixed': 'u/Rubinjo_L',\n",
       "  'key_color': '',\n",
       "  'name': 't5_5ga0v8',\n",
       "  'is_default_banner': True,\n",
       "  'url': '/user/Rubinjo_L/',\n",
       "  'quarantine': False,\n",
       "  'banner_size': None,\n",
       "  'user_is_moderator': True,\n",
       "  'accept_followers': True,\n",
       "  'public_description': '',\n",
       "  'link_flair_enabled': False,\n",
       "  'disable_contributor_requests': False,\n",
       "  'subreddit_type': 'user',\n",
       "  'user_is_subscriber': False},\n",
       " 'pref_show_presence': True,\n",
       " 'snoovatar_img': 'https://i.redd.it/snoovatar/avatars/7e1baabd-7daf-4774-a95d-92829e511322.png',\n",
       " 'snoovatar_size': [380, 600],\n",
       " 'gold_expiration': None,\n",
       " 'has_gold_subscription': False,\n",
       " 'is_sponsor': False,\n",
       " 'num_friends': 0,\n",
       " 'features': {'mod_service_mute_writes': True,\n",
       "  'promoted_trend_blanks': True,\n",
       "  'show_amp_link': True,\n",
       "  'mweb_link_tab': {'owner': 'growth',\n",
       "   'variant': 'control_2',\n",
       "   'experiment_id': 404},\n",
       "  'is_email_permission_required': True,\n",
       "  'mod_awards': True,\n",
       "  'mweb_xpromo_revamp_v3': {'owner': 'growth',\n",
       "   'variant': 'control_1',\n",
       "   'experiment_id': 480},\n",
       "  'mweb_xpromo_revamp_v2': {'owner': 'growth',\n",
       "   'variant': 'treatment_1',\n",
       "   'experiment_id': 457},\n",
       "  'awards_on_streams': True,\n",
       "  'mweb_xpromo_modal_listing_click_daily_dismissible_ios': True,\n",
       "  'chat_subreddit': True,\n",
       "  'cookie_consent_banner': True,\n",
       "  'modlog_copyright_removal': True,\n",
       "  'do_not_track': True,\n",
       "  'mod_service_mute_reads': True,\n",
       "  'chat_user_settings': True,\n",
       "  'use_pref_account_deployment': True,\n",
       "  'mweb_xpromo_interstitial_comments_ios': True,\n",
       "  'mweb_xpromo_modal_listing_click_daily_dismissible_android': True,\n",
       "  'premium_subscriptions_table': True,\n",
       "  'mweb_xpromo_interstitial_comments_android': True,\n",
       "  'mweb_nsfw_xpromo': {'owner': 'growth',\n",
       "   'variant': 'control_1',\n",
       "   'experiment_id': 361},\n",
       "  'noreferrer_to_noopener': True,\n",
       "  'chat_group_rollout': True,\n",
       "  'resized_styles_images': True,\n",
       "  'spez_modal': True,\n",
       "  'mweb_sharing_clipboard': {'owner': 'growth',\n",
       "   'variant': 'control_2',\n",
       "   'experiment_id': 315},\n",
       "  'expensive_coins_package': True},\n",
       " 'can_edit_name': False,\n",
       " 'verified': True,\n",
       " 'new_modmail_exists': None,\n",
       " 'pref_autoplay': True,\n",
       " 'coins': 0,\n",
       " 'has_paypal_subscription': False,\n",
       " 'has_subscribed_to_premium': False,\n",
       " 'id': 'fn6gzhcl',\n",
       " 'has_stripe_subscription': False,\n",
       " 'oauth_client_id': '28v86Rmdy0t3zpLsABIlaw',\n",
       " 'can_create_subreddit': True,\n",
       " 'over_18': False,\n",
       " 'is_gold': False,\n",
       " 'is_mod': False,\n",
       " 'awarder_karma': 0,\n",
       " 'suspension_expiration_utc': None,\n",
       " 'has_verified_email': True,\n",
       " 'is_suspended': False,\n",
       " 'pref_video_autoplay': True,\n",
       " 'has_android_subscription': False,\n",
       " 'in_redesign_beta': True,\n",
       " 'icon_img': 'https://styles.redditmedia.com/t5_5ga0v8/styles/profileIcon_snoo7e1baabd-7daf-4774-a95d-92829e511322-headshot.png?width=256&amp;height=256&amp;crop=256:256,smart&amp;s=5bf6cac6695af43722caff15194db1958f1fc158',\n",
       " 'has_mod_mail': False,\n",
       " 'pref_nightmode': False,\n",
       " 'awardee_karma': 0,\n",
       " 'hide_from_robots': False,\n",
       " 'password_set': True,\n",
       " 'link_karma': 1,\n",
       " 'force_password_reset': False,\n",
       " 'total_karma': 1,\n",
       " 'seen_give_award_tooltip': False,\n",
       " 'inbox_count': 0,\n",
       " 'seen_premium_adblock_modal': False,\n",
       " 'pref_top_karma_subreddits': True,\n",
       " 'has_mail': False,\n",
       " 'pref_show_snoovatar': False,\n",
       " 'name': 'Rubinjo_L',\n",
       " 'pref_clickgadget': 5,\n",
       " 'created': 1638881905.0,\n",
       " 'gold_creddits': 0,\n",
       " 'created_utc': 1638881905.0,\n",
       " 'has_ios_subscription': False,\n",
       " 'pref_show_twitter': False,\n",
       " 'in_beta': False,\n",
       " 'comment_karma': 0,\n",
       " 'accept_followers': True,\n",
       " 'has_subscribed': True,\n",
       " 'linked_identities': [],\n",
       " 'seen_subreddit_chat_ftux': False}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from auth import CLIENT_ID, SECRET_KEY, REDDIT_USERNAME, REDDIT_PASSWORD\n",
    "\n",
    "import requests\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_KEY)\n",
    "\n",
    "data = {\n",
    "    \"grant_type\": \"password\",\n",
    "    \"username\": REDDIT_USERNAME,\n",
    "    \"password\": REDDIT_PASSWORD\n",
    "}\n",
    "\n",
    "headers = {\"User-Agent\": \"MyAPI/0.0.1\"}\n",
    "\n",
    "res = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth=auth, data=data, headers=headers)\n",
    "\n",
    "TOKEN = res.json()[\"access_token\"]\n",
    "\n",
    "headers[\"Authorization\"] = f'bearer {TOKEN}'\n",
    "\n",
    "requests.get(\"https://oauth.reddit.com/api/v1/me\", headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rxeddx in the stocks subreddit does not have enough comments.\n",
      "rxdv3o in the BizSMG subreddit does not have enough comments.\n",
      "\n",
      "Top 3 subreddits used:\n",
      "stocks          6\n",
      "BizSMG          6\n",
      "Kant_sleep13    4\n",
      "Name: subreddit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Use company name, stock ticker and/or abbreviation of company\n",
    "SEARCH = [\"Apple\", \"AAPL\"]\n",
    "\n",
    "df_reddit = pd.DataFrame()\n",
    "\n",
    "for term in SEARCH:\n",
    "    payload = {\"q\": term, \"limit\": \"5\", \"sort\": \"new\"}\n",
    "\n",
    "    res = requests.get(\"https://oauth.reddit.com/r/subreddits/search\", headers=headers, params=payload)\n",
    "    for post in res.json()[\"data\"][\"children\"]:\n",
    "        df_reddit = df_reddit.append({\n",
    "            \"subreddit\": post[\"data\"][\"subreddit\"],\n",
    "            \"postid\": post[\"data\"][\"id\"],\n",
    "            \"text\": post[\"data\"][\"title\"] + \" \" + post[\"data\"][\"selftext\"],\n",
    "            \"created\": datetime.fromtimestamp(post[\"data\"][\"created\"])\n",
    "        }, ignore_index=True)\n",
    "\n",
    "df_reddit = df_reddit.drop_duplicates(\"postid\", ignore_index=True)\n",
    "\n",
    "for index, item in df_reddit.iterrows():\n",
    "    payload = {\"limit\": \"5\", \"sort\": \"new\"}\n",
    "\n",
    "    res = requests.get(\"https://oauth.reddit.com/r/\" + item[\"subreddit\"] + \"/comments/\" + item[\"postid\"], headers=headers, params=payload)\n",
    "    \n",
    "    for comment in res.json()[1][\"data\"][\"children\"]:\n",
    "        try:\n",
    "            df_reddit = df_reddit.append({\n",
    "                \"subreddit\": item[\"subreddit\"],\n",
    "                \"text\": comment[\"data\"][\"body\"],\n",
    "                \"created\": datetime.fromtimestamp(comment[\"data\"][\"created\"])\n",
    "            }, ignore_index=True)\n",
    "        except:\n",
    "            print(item[\"postid\"] + \" in the \" + item[\"subreddit\"] + \" subreddit does not have enough comments.\")\n",
    "        \n",
    "print(\"\\nTop 3 subreddits used:\")\n",
    "print(df_reddit[\"subreddit\"].value_counts()[:3])\n",
    "\n",
    "df_reddit = df_reddit.drop(columns=[\"subreddit\", \"postid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API\n",
    "\n",
    "Get tweets that corrospond to given keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('https://api.twitter.com/2/tweets/search/recent', {'query': 'AAPL lang:en', 'max_results': 10, 'tweet.fields': 'id,text,author_id,created_at,lang,source', 'next_token': {}})\n",
      "Endpoint Response Code: 200\n"
     ]
    }
   ],
   "source": [
    "from auth import TWITTER_TOKEN\n",
    "\n",
    "def auth():\n",
    "    return TWITTER_TOKEN\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def create_url(keyword, max_results = 10):\n",
    "    \n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "    # Change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'max_results': max_results,\n",
    "                    'tweet.fields': 'id,text,author_id,created_at,lang,source',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "# Inputs for the request\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"AAPL lang:en\"\n",
    "max_results = 10\n",
    "\n",
    "url = create_url(keyword, max_results)\n",
    "print(url)\n",
    "json_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "df_twitter_dirty = pd.DataFrame.from_dict(json_response[\"data\"])\n",
    "df_twitter_dirty = df_twitter_dirty.drop(columns=[\"author_id\", \"source\", \"lang\", \"id\"])\n",
    "\n",
    "df_twitter = pd.DataFrame()\n",
    "\n",
    "for index, item in df_twitter_dirty.iterrows():\n",
    "    df_twitter = df_twitter.append({\n",
    "                \"text\": item[\"text\"],\n",
    "                \"created\": datetime.fromisoformat(item[\"created_at\"].replace(\"Z\", \"\"))\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment of collected data\n",
    "\n",
    "Add data from Reddit and Twitter together and get the estimated sentiment from the trained NN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wider release for Thrashed Apple? I picked up ...</td>\n",
       "      <td>2022-01-06 16:19:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Should I continue learning android development...</td>\n",
       "      <td>2022-01-06 16:19:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[H] Student Beans Accounts one Year -$5 [W] Pa...</td>\n",
       "      <td>2022-01-06 16:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apples, Oranges, battle lines. Mushroom cloud.</td>\n",
       "      <td>2022-01-06 16:15:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are your days usually like, and how much ...</td>\n",
       "      <td>2022-01-06 16:15:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stock Watch List January 6, 2022 ***Good morni...</td>\n",
       "      <td>2022-01-06 14:51:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This Subs Environment is so Toxic on days the ...</td>\n",
       "      <td>2022-01-06 14:16:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Top stock option open interest changes $AAPL $...</td>\n",
       "      <td>2022-01-06 13:58:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thu Jan 6 23:50:25 2022 NASDAQ:TSLA / 127\\n\\n[...</td>\n",
       "      <td>2022-01-06 13:50:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$AAPL Awaiting Buy Signal. Chart by UltraAlgo....</td>\n",
       "      <td>2022-01-06 13:49:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             created\n",
       "0  Wider release for Thrashed Apple? I picked up ... 2022-01-06 16:19:30\n",
       "1  Should I continue learning android development... 2022-01-06 16:19:05\n",
       "2  [H] Student Beans Accounts one Year -$5 [W] Pa... 2022-01-06 16:18:30\n",
       "3    Apples, Oranges, battle lines. Mushroom cloud.  2022-01-06 16:15:50\n",
       "4  What are your days usually like, and how much ... 2022-01-06 16:15:11\n",
       "5  Stock Watch List January 6, 2022 ***Good morni... 2022-01-06 14:51:53\n",
       "6  This Subs Environment is so Toxic on days the ... 2022-01-06 14:16:01\n",
       "7  Top stock option open interest changes $AAPL $... 2022-01-06 13:58:42\n",
       "8  Thu Jan 6 23:50:25 2022 NASDAQ:TSLA / 127\\n\\n[... 2022-01-06 13:50:25\n",
       "9  $AAPL Awaiting Buy Signal. Chart by UltraAlgo.... 2022-01-06 13:49:07"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_dirty = pd.concat([df_reddit, df_twitter], ignore_index=True)\n",
    "df_total_dirty.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_text</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 0, 758, 14, 6320, 223, 194, 47, 370, 214, ...</td>\n",
       "      <td>2022-01-06 16:19:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 494, 47, 776, 652, 74, 1910, 839, 494, 47,...</td>\n",
       "      <td>2022-01-06 16:19:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2626, 2180, 2627, 2205, 6761, 13, 34, 182,...</td>\n",
       "      <td>2022-01-06 16:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 223, 44, 5043, 44, 1615, 1577, 57, 0, 4941...</td>\n",
       "      <td>2022-01-06 16:15:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 159, 100, 121, 18, 765, 162, 44, 27, 277, ...</td>\n",
       "      <td>2022-01-06 16:15:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2976, 503, 1457, 2671, 915, 44, 0, 961, 96...</td>\n",
       "      <td>2022-01-06 14:51:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 59, 5532, 0, 122, 124, 4561, 8, 18, 16, 0,...</td>\n",
       "      <td>2022-01-06 14:16:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 552, 2976, 1704, 639, 2050, 289, 108, 6412...</td>\n",
       "      <td>2022-01-06 13:58:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 8385, 1805, 915, 0, 0, 0, 77, 0, 904, 0, 2...</td>\n",
       "      <td>2022-01-06 13:50:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 108, 6412, 0, 440, 4927, 57, 1220, 505, 0,...</td>\n",
       "      <td>2022-01-06 13:49:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        encoded_text             created\n",
       "0  [1, 0, 758, 14, 6320, 223, 194, 47, 370, 214, ... 2022-01-06 16:19:30\n",
       "1  [1, 494, 47, 776, 652, 74, 1910, 839, 494, 47,... 2022-01-06 16:19:05\n",
       "2  [1, 2626, 2180, 2627, 2205, 6761, 13, 34, 182,... 2022-01-06 16:18:30\n",
       "3  [1, 223, 44, 5043, 44, 1615, 1577, 57, 0, 4941... 2022-01-06 16:15:50\n",
       "4  [1, 159, 100, 121, 18, 765, 162, 44, 27, 277, ... 2022-01-06 16:15:11\n",
       "5  [1, 2976, 503, 1457, 2671, 915, 44, 0, 961, 96... 2022-01-06 14:51:53\n",
       "6  [1, 59, 5532, 0, 122, 124, 4561, 8, 18, 16, 0,... 2022-01-06 14:16:01\n",
       "7  [1, 552, 2976, 1704, 639, 2050, 289, 108, 6412... 2022-01-06 13:58:42\n",
       "8  [1, 8385, 1805, 915, 0, 0, 0, 77, 0, 904, 0, 2... 2022-01-06 13:50:25\n",
       "9  [1, 108, 6412, 0, 440, 4927, 57, 1220, 505, 0,... 2022-01-06 13:49:07"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total = pd.DataFrame()\n",
    "\n",
    "for index, item in df_total_dirty.iterrows():\n",
    "    df_total = df_total.append({\n",
    "        \"encoded_text\": encode_and_pad(tokenization(normalize_text(item[\"text\"])), SEQ_LENGTH),\n",
    "        \"created\": item[\"created\"]\n",
    "    }, ignore_index=True)\n",
    "\n",
    "df_total.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_cat</th>\n",
       "      <th>label</th>\n",
       "      <th>created</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-01-06 16:19:30</td>\n",
       "      <td>Wider release for Thrashed Apple? I picked up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-01-06 16:19:05</td>\n",
       "      <td>Should I continue learning android development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-01-06 16:18:30</td>\n",
       "      <td>[H] Student Beans Accounts one Year -$5 [W] Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-01-06 16:15:50</td>\n",
       "      <td>Apples, Oranges, battle lines. Mushroom cloud.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-01-06 16:15:11</td>\n",
       "      <td>What are your days usually like, and how much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-01-06 14:51:53</td>\n",
       "      <td>Stock Watch List January 6, 2022 ***Good morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-01-06 14:16:01</td>\n",
       "      <td>This Subs Environment is so Toxic on days the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2022-01-06 13:58:42</td>\n",
       "      <td>Top stock option open interest changes $AAPL $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-01-06 13:50:25</td>\n",
       "      <td>Thu Jan 6 23:50:25 2022 NASDAQ:TSLA / 127\\n\\n[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-01-06 13:49:07</td>\n",
       "      <td>$AAPL Awaiting Buy Signal. Chart by UltraAlgo....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_cat     label             created  \\\n",
       "0        1.0   neutral 2022-01-06 16:19:30   \n",
       "1        0.0  negative 2022-01-06 16:19:05   \n",
       "2        2.0  positive 2022-01-06 16:18:30   \n",
       "3        2.0  positive 2022-01-06 16:15:50   \n",
       "4        1.0   neutral 2022-01-06 16:15:11   \n",
       "5        2.0  positive 2022-01-06 14:51:53   \n",
       "6        1.0   neutral 2022-01-06 14:16:01   \n",
       "7        1.0   neutral 2022-01-06 13:58:42   \n",
       "8        2.0  positive 2022-01-06 13:50:25   \n",
       "9        2.0  positive 2022-01-06 13:49:07   \n",
       "\n",
       "                                                text  \n",
       "0  Wider release for Thrashed Apple? I picked up ...  \n",
       "1  Should I continue learning android development...  \n",
       "2  [H] Student Beans Accounts one Year -$5 [W] Pa...  \n",
       "3    Apples, Oranges, battle lines. Mushroom cloud.   \n",
       "4  What are your days usually like, and how much ...  \n",
       "5  Stock Watch List January 6, 2022 ***Good morni...  \n",
       "6  This Subs Environment is so Toxic on days the ...  \n",
       "7  Top stock option open interest changes $AAPL $...  \n",
       "8  Thu Jan 6 23:50:25 2022 NASDAQ:TSLA / 127\\n\\n[...  \n",
       "9  $AAPL Awaiting Buy Signal. Chart by UltraAlgo....  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_map(label):\n",
    "    if label == 0:\n",
    "        return \"negative\"\n",
    "    elif label == 1:\n",
    "        return \"neutral\"\n",
    "    else: #2\n",
    "        return \"positive\"\n",
    "\n",
    "df_labels = pd.DataFrame()\n",
    "\n",
    "h0, c0 =  model.init_hidden(1)\n",
    "h0 = h0.to(device)\n",
    "c0 = c0.to(device)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "with torch.set_grad_enabled(False):\n",
    "\n",
    "    for index, item in df_total.iterrows():\n",
    "        out, hidden = model(torch.tensor([item[\"encoded_text\"]]).to(device), (h0, c0))\n",
    "        _, preds = torch.max(out, 1)\n",
    "        preds = preds.to(device).tolist()\n",
    "        df_labels = df_labels.append({\n",
    "            \"label_cat\": preds[0],\n",
    "            \"label\": label_map(preds[0]),\n",
    "            \"created\": item[\"created\"]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "df_labels[\"text\"] = df_total_dirty[\"text\"]\n",
    "\n",
    "df_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc5ElEQVR4nO3deZRdZZ3u8e9jSJBJUBMQMjAoIGADahmwQQm6hIRFN9iN3Ukjg8NK4xWHqxcbUMFutVdf6dW2KBrTbW70ytC4IBrvAgJ3qYAgNhVkhtC5EaQISpinKCY+94/9lmyKXVWnkto5Fer5rHVWnfMOe//OCZzf2e+797tlm4iIiIFe1u0AIiJibEqCiIiIRkkQERHRKAkiIiIaJUFERESjJIiIiGiUBBFjlqQFkj7b7TiaSNpb0i8kPSXpo92OZziSLOl13Y4jNi9JEDEikg6VdL2kJyQ9Kuk6SW8Zhe2eLOmn9TLbp9j+/MZuewNi+Zyk7w7T7FPAT2xvZ/vcUdz3yeXL/K9Ga5ttKJ+RJc0cpF6SVkm6s6HuJ5J+K+lpSQ9LulTSzqVusaQvtB1/dCYJIjom6RXA/wG+CrwKmAr8PfC7bsbVJbsCd2xIR0lbDFF9EvBo+TsmSRJwAkPH+XZgR2CPQX5AnGp7W2AvYAfgyy2EGhspCSJGYi8A2xfaXm97re0rbd/a30DS+yXdJekxScsk7Vqrs6RTJP1XqT+v/NLcB1gAvLX8qny8tP/jr0lJsyT1SfqUpIckPSjpWElHSbqnHM2cWdvXyySdLun/SXpE0sWSXlXqdiuxnCTpV+VX7KdL3WzgTOCvSyy3DPwQJP0IOBz4Wmmzl6TtJX1H0hpJ90n6jKSXlfYnlyOtL0t6FPhc04dbPqvDgPnAkZJ2qtX1v/8zS7z3Sjq+Vr+4DMldVYa9rq5/9gP2s6Wkfy7v/Tel31aD/7O/yNuAXYCPAXMlTWpocxLwA+Ayhkh2th8FLgHeMIL9xyaSBBEjcQ+wXtK3Jc2R9Mp6paRjqb5c/wKYAlwLXDhgG0cDbwEOAP4KONL2XcApwM9sb2t7h0H2/xrg5VRHLmcB/wa8F3gz1ZfWWZL2KG0/ChxL9YW7C/AYcN6A7R0K7A28s/Tdx/YVwD8C/1FiOWBgELbfUd7bqaXNPVRHVdsDe5R9ngi8r9btIGAV1a/qLw7y/k4Eem1fAtwFHD+g/jXA5PL+TwIWStq7Vn888PnS5mbg/EH28z+pkv2BwOt4/vPs1EnAD4H/KK+PrldK2ho4ruz/fAZPIkiaDPwl8IsR7D82Fdt55NHxA9gHWAz0AeuApcBOpe5y4AO1ti8DngV2La8NHFqrvxg4vTw/GfjpgH0tBr5Qns8C1gITyuvtyvYOqrVfDhxbnt8FvLNWtzPwe2ALYLfSd1qt/j+BueX554DvDvM5/AT4YHk+gWqYbd9a/d9SzVH0v7dfdfDZ/hfw8fL8DOCWWt2s8nlvM+Dz+2zts7qoVrctsB6YXvvsXwcIeAZ4ba3tW4FfdvjvvzXwZO1z/ibwgwFt3gusKZ/1lsDjwLsHfHbPlvIHqJLIlIH/5nl0/5EjiBgR23fZPtn2NKphgV2Afy3VuwJfkfR4GSZ6lOoLaWptE7+uPX+W6ousU4/YXl+ery1/f1OrX1vb3q7Aklosd1F9Ye5Ua78xsdRNBiYB99XK7uOF7/v+oTYg6RBgd+CiUnQB8CeSDqw1e8z2MwP2sUvTPmw/TfX51+uhOrLbGlhe+2yuKOWdeDdVorqsvD4fmCOp3v8k4GLb62z/DriUFw8zfdT2Dran2j7e9poO9x+b0FCTZRFDsn23pMVUv5ah+oL6ou3BhjaG3NyoBfZ8LO+3fd3ACkm7jXIsD1MdnewK9J+1M4Pq13Gn2zyJKpneXM0B/9GJVMNFAK+UtE0tScwAbq+1nd7/RNK2VCcSrG6IdS2wn+0HGLmTqBLpr0qcAiYC84BzJU0D3gHMlPSXpc/WwMslTbb98AbsM7okRxDRMUmvl/TJ8iWApOlUXww3lCYLgDMk7Vfqt5f0ng43/xtg2mBj1RtgAfDF/olaSVMkHTOCWHbrn2QeTjmqubjsb7uyz08Aw50qS4nt5VTzMfOp5gX6Hx8BjtcLz3r6e0mTJL2Nauz/e7W6o1SdhjyJai7i57ZfcORi+w9UczdflrRj2f9USUfW4rGkWQ1xTqWarzm6FuMBVHMa/UcIJ1DNVe1da7MX1ZDkvE4+D2CCpJfXHqP130SMUBJEjMRTVJOtP5f0DFViuB34JIDtJVRfFhdJerLUzelw2z+iOm3015JG41fmV6jmR66U9FSJ9aAO+/Z/6T4i6aYO+3yEamx/FfBTqiGiRR32PZbqV/13bP+6/wF8i2p+Y3Zp92uqyfbVVEM7p9i+u7adC4CzqYaW3syLJ7n7/R2wErih/Dv9X6ovdEryfxq4raHfCcDNrs5cq8d5LrC/pDdQJYqv1+tLmwV0furu6eXz6H/8qMN+Mcpk54ZBEWNd+UX/3TL301S/GOiz/ZmN3M97qYafztiY7cRLQ+YgIuKPbHc0LBbjQ2tDTJKmS/qxqoum7pD0sYY2knSupJWSbpX0plrdbEkrSt3pbcUZERHNWhtiUrW2ys62b5K0Hc+fo35nrc1RVGO3R1GND3/F9kGSJlBNdL2LanLrRmBevW9ERLSrtSMI2w/avqk8f4rqPPSpA5odQzUxZ9s3ADuUxDITWGl7le3nqM4N7/QMlIiIGAWbZA6inHf+RuDnA6qm8sILiPpKWVN54xkokuZTnR7INtts8+bXv/71oxN0RMQ4sHz58odtN14o2XqCKBfsXEK1hMCTA6sbuniI8hcX2guBhQA9PT3u7e3diGgjIsYXSfcNVtdqgpA0kSo5nG/70oYmfdSu/gSmUZ3jPWmQ8oiI2ETaPItJVBf63GX7XwZpthQ4sZzNdDDwhO0HqSal95S0e7mKcm5pGxERm0ibRxCHUF15eZukm0vZmVTrx2B7AdWCX0dRXdX5LGV5ZNvrJJ0KLKO6knSR7Q26OUtERGyY1hKE7Z/SPJdQb2Pgw4PUXcbzK0ZGRMQmlrWYIiKiURJEREQ0SoKIiIhGSRAREdEoCSIiIholQURERKMkiIiIaJQEERERjZIgIiKiURJEREQ0SoKIiIhGSRAREdEoCSIiIholQURERKMkiIiIaJQEERERjZIgIiKiURJEREQ0au2Wo5IWAUcDD9l+Q0P9acDxtTj2AabYflTSvcBTwHpgne2etuKMiIhmbR5BLAZmD1Zp+xzbB9o+EDgDuNr2o7Umh5f6JIeIiC5oLUHYvgZ4dNiGlXnAhW3FEhERI9f1OQhJW1MdaVxSKzZwpaTlkuZ3J7KIiPGttTmIEfgz4LoBw0uH2F4taUfgKkl3lyOSFykJZD7AjBkz2o82ImKc6PoRBDCXAcNLtleXvw8BS4CZg3W2vdB2j+2eKVOmtBpoRMR40tUEIWl74DDgB7WybSRt1/8cOAK4vTsRRkSMX22e5nohMAuYLKkPOBuYCGB7QWn2buBK28/Uuu4ELJHUH98Ftq9oK86IiGjWWoKwPa+DNoupToetl60CDmgnqoiI6NRYmIOIiIgxKAkiIiIaJUFERESjJIiIiGiUBBEREY2SICIiolESRERENEqCiIiIRkkQERHRKAkiIiIaJUFERESjJIiIiGiUBBEREY2SICIiolESRERENEqCiIiIRkkQERHRKAkiIiIaJUFERESj1hKEpEWSHpJ0+yD1syQ9Ienm8jirVjdb0gpJKyWd3laMERExuDaPIBYDs4dpc63tA8vjHwAkTQDOA+YA+wLzJO3bYpwREdGgtQRh+xrg0Q3oOhNYaXuV7eeAi4BjRjW4iIgYVrfnIN4q6RZJl0var5RNBe6vtekrZY0kzZfUK6l3zZo1bcYaETGudDNB3ATsavsA4KvA90u5Gtp6sI3YXmi7x3bPlClTRj/KiIhxqmsJwvaTtp8uzy8DJkqaTHXEML3WdBqwugshRkSMa11LEJJeI0nl+cwSyyPAjcCeknaXNAmYCyztVpwREePVFm1tWNKFwCxgsqQ+4GxgIoDtBcBxwIckrQPWAnNtG1gn6VRgGTABWGT7jrbijIiIZqq+k18aenp63Nvb2+0wIiI2G5KW2+5pquv2WUwRETFGJUFERESjJIiIiGiUBBEREY2SICIiolESRERENEqCiIiIRkkQERHRKAkiIiIaJUFERESj1tZiigj4/i8e4JxlK1j9+Fp22WErTjtyb45946C3N4kYU5IgIlry/V88wBmX3sba368H4IHH13LGpbcBJEnEZiFDTBEtOWfZij8mh35rf7+ec5at6FJEESOTBBHRktWPrx1RecRYkwQR0ZJddthqROURY00SRERLTjtyb7aaOOEFZVtNnMBpR+7dpYgiRiaT1BEt6Z+IzllMsblKgoho0bFvnJqEEJut1oaYJC2S9JCk2wepP17SreVxvaQDanX3SrpN0s2Scg/RiIguaHMOYjEwe4j6XwKH2d4f+DywcED94bYPHOxeqRER0a7WhphsXyNptyHqr6+9vAGY1lYsERExcmPlLKYPAJfXXhu4UtJySfOH6ihpvqReSb1r1qxpNciIiPGk65PUkg6nShCH1ooPsb1a0o7AVZLutn1NU3/bCynDUz09PW494IiIcaKrRxCS9gf+HTjG9iP95bZXl78PAUuAmd2JMCJi/OpagpA0A7gUOMH2PbXybSRt1/8cOAJoPBMqIiLa09EQk6RDbF83XNmA+guBWcBkSX3A2cBEANsLgLOAVwNflwSwrpyxtBOwpJRtAVxg+4oRvq+IiNhIsocftpd0k+03DVfWbT09Pe7tzWUTERGdkrR8sMsJhjyCkPRW4E+BKZI+Uat6BTChuVdERLwUDDfENAnYtrTbrlb+JHBcW0FFRET3DZkgbF8NXC1pse37NlFMERExBnR6HcSWkhYCu9X72H5HG0FFRET3dZogvgcsoLpmYf0wbSMi4iWg0wSxzvY3Wo0kIiLGlE4vlPuhpP8maWdJr+p/tBpZRER0VadHECeVv6fVygzsMbrhRETEWNFRgrC9e9uBRETE2NLREJOkrSV9ppzJhKQ9JR3dbmgREdFNnc5B/C/gOaqrqgH6gC+0ElFERIwJnSaI19r+EvB7ANtrAbUWVUREdF2nCeI5SVtRTUwj6bXA71qLKiIiuq7Ts5jOBq4Apks6HzgEOLmtoCIiovs6PYvpKkk3AQdTDS19zPbDrUYWERFdNZI7yk2lWuJ7EvB2SX/RTkgRETEWdHpHuUXA/sAdwB9KsaluGRoRES9Bnc5BHGx731YjiYiIMaXTIaafSRpRgpC0SNJDkm4fpF6SzpW0UtKtkt5Uq5staUWpO30k+42IiNHRaYL4NlWSWFG+zG+TdOswfRYDs4eonwPsWR7zgW8ASJoAnFfq9wXmjTQ5RUTExut0iGkRcAJwG8/PQQzJ9jWSdhuiyTHAd2wbuEHSDpJ2prop0UrbqwAkXVTa3tlhrBERMQo6TRC/sr10lPc9Fbi/9rqvlDWVHzTYRiTNpzoCYcaMGaMcYkTE+NVpgrhb0gXAD6ldQW17Y85ialqqw0OUN7K9EFgI0NPTM2i7iIgYmU4TxFZUieGIWtnGnubaB0yvvZ4GrKa6zqKpPCIiNqFOr6R+Xwv7XgqcWuYYDgKesP2gpDXAnpJ2Bx4A5gJ/08L+IyJiCEMmCEmfsv0lSV+lYZjH9keH6HshMAuYLKmPaj2niaXfAuAy4ChgJfAs8L5St07SqcAyqiu3F9m+Y+RvLSIiNsZwRxB3lb+9I92w7XnD1Bv48CB1l1ElkIiI6JIhE4TtH5anz9r+Xr1O0ntaiyoiIrqu0wvlzuiwLCIiXiKGm4OYQzVPMFXSubWqVwDr2gwsIiK6a7g5iNVU8w9/DiyvlT8F/Pe2goqIiO4bbg7iFuAWSRfY/v0miikiIsaATi+Umynpc8CupY+oTkTao63AIiKiuzpNEN+iGlJaDqxvL5yIiBgrOk0QT9i+vNVIIiJiTOk0QfxY0jlUay/VF+u7qZWoIiKi6zpNEP3LbffUygy8Y3TDiYiIsaLTxfoObzuQiIgYWzq6klrSTpK+Jeny8npfSR9oN7SIiOimTpfaWEy1uuou5fU9wMdbiCciIsaIThPEZNsXU+5HbXsdOd01IuIlrdME8YykV1PuCSHpYOCJ1qKKiIiu6/Qspk9Q3QHutZKuA6YAx7UWVUREdN2QRxCS3iLpNeV6h8OAM6mug7iS6p7SERHxEjXcENM3gefK8z8FPg2cBzwGLGwxroiI6LLhEsQE24+W538NLLR9ie3PAq8bbuOSZktaIWmlpNMb6k+TdHN53C5pvaRXlbp7Jd1W6kZ8y9OIiNg4wyYISf3zFO8EflSrG+5mQxOojjbmAPsC8yTtW29j+xzbB9o+kOoOdVfXEhLA4aW+fgV3RERsAsNNUl8IXC3pYWAtcC2ApNcx/FlMM4GVtleVPhcBxwB3DtJ+XtlfRESMAUMeQdj+IvBJqgvlDrXtWr+PDLPtqcD9tdd9pexFJG0NzAYuqe8euFLScknzB9uJpPmSeiX1rlmzZpiQIiKiU8Oe5mr7hoayezrYtpo2N0jbPwOuGzC8dIjt1ZJ2BK6SdLftaxpiWUiZMO/p6Rls+xERMUKdXii3IfqA6bXX06jucd1kLgOGl2yvLn8fApZQDVlFRMQm0maCuBHYU9LukiZRJYGlAxtJ2p7qGosf1Mq2kbRd/3PgCOD2FmONiIgBOr2SesRsr5N0KtUifxOARbbvkHRKqV9Qmr4buNL2M7XuOwFLJPXHeIHtK9qKNSIiXkzPzztv/np6etzbm0smIiI6JWn5YJcStDnEFBERm7EkiIiIaJQEERERjZIgIiKiURJEREQ0SoKIiIhGSRAREdEoCSIiIholQURERKMkiIiIaJQEERERjZIgIiKiURJEREQ0SoKIiIhGSRAREdEoCSIiIholQURERKMkiIiIaNRqgpA0W9IKSSslnd5QP0vSE5JuLo+zOu0bERHt2qKtDUuaAJwHvAvoA26UtNT2nQOaXmv76A3sGxERLWnzCGImsNL2KtvPARcBx2yCvhERMQraTBBTgftrr/tK2UBvlXSLpMsl7TfCvkiaL6lXUu+aNWtGI+6IiKDdBKGGMg94fROwq+0DgK8C3x9B36rQXmi7x3bPlClTNjTWiIgYoM0E0QdMr72eBqyuN7D9pO2ny/PLgImSJnfSNyIi2tVmgrgR2FPS7pImAXOBpfUGkl4jSeX5zBLPI530jYiIdrV2FpPtdZJOBZYBE4BFtu+QdEqpXwAcB3xI0jpgLTDXtoHGvm3FGhERL6bq+/iloaenx729vd0OIyJisyFpue2eprpcSR0REY2SICIiolESRERENEqCiIiIRkkQERHRKAkiIiIaJUFERESjJIiIiGiUBBEREY2SICIiolESRERENEqCiIiIRkkQERHRKAkiIiIaJUFERESjJIiIiGiUBBEREY2SICIiolGrCULSbEkrJK2UdHpD/fGSbi2P6yUdUKu7V9Jtkm6WlPuIRkRsYlu0tWFJE4DzgHcBfcCNkpbavrPW7JfAYbYfkzQHWAgcVKs/3PbDbcUYERGDa/MIYiaw0vYq288BFwHH1BvYvt72Y+XlDcC0FuOJiIgRaDNBTAXur73uK2WD+QBwee21gSslLZc0v4X4IiJiCK0NMQFqKHNjQ+lwqgRxaK34ENurJe0IXCXpbtvXNPSdD8wHmDFjxsZHHRERQLtHEH3A9NrracDqgY0k7Q/8O3CM7Uf6y22vLn8fApZQDVm9iO2Ftnts90yZMmUUw4+IGN/aTBA3AntK2l3SJGAusLTeQNIM4FLgBNv31Mq3kbRd/3PgCOD2FmONiIgBWhtisr1O0qnAMmACsMj2HZJOKfULgLOAVwNflwSwznYPsBOwpJRtAVxg+4q2Yo2IiBeT3TgtsFnq6elxb28umYiI6JSk5eWH+YvkSuqIiGiUBBEREY2SICIiolESRERENEqCiIiIRkkQERHRKAkiIiIaJUFERESjJIiIiGiUBBEREY2SICIiolESRERENEqCiIiIRkkQERHRKAkiIiIaJUFERESjJIiIiGiUBBEREY2SICIiolGrCULSbEkrJK2UdHpDvSSdW+pvlfSmTvtGRES7WksQkiYA5wFzgH2BeZL2HdBsDrBnecwHvjGCvhER0aI2jyBmAittr7L9HHARcMyANscA33HlBmAHSTt32DciIlq0RYvbngrcX3vdBxzUQZupHfYFQNJ8qqMPgKclrdiImCPaMhl4uNtBRDTYdbCKNhOEGsrcYZtO+laF9kJg4chCi9i0JPXa7ul2HBEj0WaC6AOm115PA1Z32GZSB30jIqJFbc5B3AjsKWl3SZOAucDSAW2WAieWs5kOBp6w/WCHfSMiokWtHUHYXifpVGAZMAFYZPsOSaeU+gXAZcBRwErgWeB9Q/VtK9aITSDDoLHZkd04tB8REeNcrqSOiIhGSRAREdEoCSLGrcGWc5H0kVJ+h6QvDeizXNIkSW+WdFvpe64klfq3S7pJ0jpJxzXs8wpJUyWdX/Zxu6RFkiaW+sblZyRNl/RjSXeVuD5W2+Y5ku4u7ZdI2qGljyzGmSSIGJcGW85F0uFUV+3vb3s/4J9rfXYDHihX93+D6gLN/qViZpdmvwJOBi5o2OdWwKtsPwCcD7we+BNgK+CDpVnj8jPAOuCTtvcBDgY+XFt+5irgDbb3B+4BztjgDyaiJgkixqvBlnP5EPBPtn8HYPuhWp85wBVlOZhX2P6Zq7M8vgMcW9rfa/tW4A8N+5wF/KS0u6wsMWPgP6mu9YFBlp+x/aDtm0rfp4C7qFYcwPaVtteV/jfUthWxUZIgYrwabJmXvYC3Sfq5pKslvaXWZjZwRWnX19B3OHNK/z8qQ0sn1MoHi6veZzfgjcDPG/bxfuDyDmKJGFYSRIxXgy3nsgXwSqphnNOAi8u8wCRgmu1VQ/QdziHATweUfR24xva1w8RVVUrbApcAH7f9ZL2RpE9TDUWd30EsEcNqc6mNiLFssGVe+oBL+4d+JP2BaqG9/Xn+y72PFw7jDLsUjKQ9gPvLcFZ/2dnAFOBvO4ir/2jjEuB825cO2P5JwNHAO52Lm2KU5AgixqvBlnP5PvAOAEl7Ua0L9jDV8NLlAGU5mKckHVzOXjoR+MEw+3vB8JKkDwJHAvNs1+crGpefKfv5FnCX7X+pb1jSbODvgD+3/ezIP4qIZrmSOsYtSUcB/8rzy7l8sSSLRcCBwHPA/7D9I0k3Am+3vbb07QEWU52BdDnwEdsucxZLqIapfgv82vZ+kn5Y2txb+q8D7gOeKuFcavsfSiL4GlVCehZ4n+1eSYcC1wK38fwE+Jm2L5O0EtgSeKSU32D7lFH+uGIcSoKIGIakacC/2Z6zgf23BK7Lct+xuUmCiIiIRpmDiIiIRkkQERHRKAkiIiIaJUFERESjJIiIDSRpvaSby+qqt0j6hKQh/5+StJukv9lUMUZsjCSIiA231vaBZdXXd1HdPvfsYfrsBiRBxGYhp7lGbCBJT9vetvZ6D6ortCcDuwL/G9imVJ9q+3pJNwD7AL8Evg2cC/wT1UqvWwLn2f7mJnsTEUNIgojYQAMTRCl7jOo+D08Bf7D9W0l7Ahfa7pE0i+rq7KNL+/nAjra/0H9BHfAe27/clO8lokkW64sYXf2rsU4EvibpQGA91TLiTY4A9q/dfW57qpsFJUFE1yVBRIySMsS0HniIai7iN8ABVHN9vx2sG9UaTcs2SZARI5BJ6ohRIGkKsAD4Wllue3vgwbJS6wlUCwJCNfS0Xa3rMuBDtXtS7yVpGyLGgBxBRGy4rSTdTDWctI5qUrp/Ke6vA5dIeg/wY+CZUn4rsE7SLVSrwX6F6symm8pKrmsoty+N6LZMUkdERKMMMUVERKMkiIiIaJQEERERjZIgIiKiURJEREQ0SoKIiIhGSRAREdHo/wOUzmz8XI8WqAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentiment: 1.324\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "df_result = pd.DataFrame()\n",
    "\n",
    "for index, item in df_labels.iterrows():\n",
    "    if item[\"created\"].date() not in dates:\n",
    "        dates.append(item[\"created\"].date())\n",
    "\n",
    "for date in dates:\n",
    "    df_result = df_result.append({\n",
    "        \"sentiment\": df_labels[\"label_cat\"][df_labels[\"created\"].apply(lambda date: date.date()) == date].mean(),\n",
    "        \"date\": date.strftime('%d/%m/%Y')\n",
    "    }, ignore_index=True)\n",
    "\n",
    "plt.plot(df_result[\"date\"].values.tolist(), df_result[\"sentiment\"].values.tolist(), marker=\"o\")\n",
    "plt.ylim(0, 2)\n",
    "plt.title(\"Sentiment for \" + \", \".join(SEARCH))\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sentiment\")\n",
    "plt.show()\n",
    "\n",
    "print(f'Average sentiment: {df_result[\"sentiment\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Stock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>172.699997</td>\n",
       "      <td>173.065002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open       Close\n",
       "Date                              \n",
       "2022-01-06  172.699997  173.065002"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "df['StartDate'] = pd.to_datetime(df_result['date'], format='%d/%m/%Y')\n",
    "least_recent_date = df['StartDate'].min()\n",
    "most_recent_date = df['StartDate'].max()\n",
    "most_recent_date += datetime.timedelta(days=1)\n",
    "end_date = most_recent_date.strftime('%Y-%m-%d')\n",
    "start_date = least_recent_date.strftime('%Y-%m-%d')\n",
    "\n",
    "apple = yf.Ticker(\"AAPL\")\n",
    "df_stock = apple.history(interval=\"1d\", start=start_date, end=end_date)\n",
    "df_stock = df_stock.drop( df_stock.index.to_list()[0] ,axis = 0 )\n",
    "df_stock = df_stock.drop([\"High\", \"Low\", \"Volume\", \"Dividends\", \"Stock Splits\"], axis=1)\n",
    "df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>-0.365005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            stock_change\n",
       "Date                    \n",
       "2022-01-06     -0.365005"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock[\"stock_change\"] = df_stock[\"Open\"] - df_stock[\"Close\"]\n",
    "df_stock = df_stock.drop([\"Open\", \"Close\"], axis=1)\n",
    "df_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stock_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06/01/2022</td>\n",
       "      <td>1.323529</td>\n",
       "      <td>-0.365005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sentiment  stock_change\n",
       "0  06/01/2022   1.323529     -0.365005"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[\"stock_change\"] = df_stock[\"stock_change\"].values.tolist()\n",
    "df_result = df_result[[\"date\", \"sentiment\", \"stock_change\"]]\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7655dccab25508e2b7250356d0c4fb2b1981e06266edd0cc1bf19819e9b5c49e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
